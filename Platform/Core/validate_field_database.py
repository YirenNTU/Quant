#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ” Field Database Validator - æ¬„ä½è³‡æ–™åº«é©—è­‰å™¨
================================================================================

é©—è­‰é …ç›®:
1. å®Œæ•´æ€§æª¢æŸ¥ - æ‰€æœ‰æ¬„ä½æª”æ¡ˆæ˜¯å¦å­˜åœ¨
2. è³‡æ–™å“è³ªæª¢æŸ¥ - ç¼ºå€¼æ¯”ä¾‹ã€ç•°å¸¸å€¼
3. æ•¸å€¼æ­£ç¢ºæ€§ - èˆ‡åŸå§‹è³‡æ–™æ¯”å°
4. ä¸€è‡´æ€§æª¢æŸ¥ - è·¨æ¬„ä½é‚è¼¯ä¸€è‡´æ€§
5. æ™‚é–“ç¯„åœæª¢æŸ¥ - æ—¥æœŸé€£çºŒæ€§

Author: Investment AI Platform
Version: 1.0
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from io import StringIO
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è·¯å¾‘è¨­å®š
SCRIPT_DIR = Path(__file__).parent
PLATFORM_DIR = SCRIPT_DIR.parent
PROJECT_ROOT = PLATFORM_DIR.parent

# è³‡æ–™åº«è·¯å¾‘
FIELD_DB_DIR = PLATFORM_DIR / "FieldDB"
SOURCE_DB_DIR = PROJECT_ROOT / "Stock_Pool" / "Database"


class FieldDatabaseValidator:
    """æ¬„ä½è³‡æ–™åº«é©—è­‰å™¨"""
    
    def __init__(self):
        self.field_db_path = FIELD_DB_DIR
        self.source_db_path = SOURCE_DB_DIR
        self.results = {
            "completeness": {},
            "quality": {},
            "accuracy": {},
            "consistency": {},
            "summary": {}
        }
        
        # è¼‰å…¥ metadata
        self.field_map = self._load_json("_meta/field_map.json")
        self.tickers_info = self._load_json("_meta/tickers.json")
    
    def _load_json(self, rel_path: str) -> dict:
        """è¼‰å…¥ JSON"""
        path = self.field_db_path / rel_path
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _load_field(self, field: str) -> pd.DataFrame:
        """è¼‰å…¥æ¬„ä½è³‡æ–™"""
        info = self.field_map.get(field, {})
        category = info.get("category", "price")
        path = self.field_db_path / category / f"{field}.parquet"
        if path.exists():
            return pd.read_parquet(path)
        return pd.DataFrame()
    
    def _load_source(self, ticker: str) -> dict:
        """è¼‰å…¥åŸå§‹è³‡æ–™"""
        # æ‰¾æœ€æ–°çš„æª”æ¡ˆ
        pattern = f"{ticker}_*.json"
        files = list(self.source_db_path.glob(pattern))
        if not files:
            return {}
        
        latest = sorted(files)[-1]
        with open(latest, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. å®Œæ•´æ€§æª¢æŸ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def check_completeness(self) -> dict:
        """æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§"""
        print("\n" + "=" * 70)
        print("1ï¸âƒ£  å®Œæ•´æ€§æª¢æŸ¥ (Completeness)")
        print("=" * 70)
        
        results = {
            "fields_expected": len(self.field_map),
            "fields_found": 0,
            "fields_missing": [],
            "tickers_expected": len(self.tickers_info.get("tickers", [])),
            "by_category": {}
        }
        
        # æª¢æŸ¥æ¯å€‹æ¬„ä½æª”æ¡ˆ
        for field, info in self.field_map.items():
            category = info["category"]
            path = self.field_db_path / category / f"{field}.parquet"
            
            if category not in results["by_category"]:
                results["by_category"][category] = {
                    "expected": 0,
                    "found": 0,
                    "missing": []
                }
            
            results["by_category"][category]["expected"] += 1
            
            if path.exists():
                results["fields_found"] += 1
                results["by_category"][category]["found"] += 1
            else:
                results["fields_missing"].append(field)
                results["by_category"][category]["missing"].append(field)
        
        # è¼¸å‡ºçµæœ
        print(f"\n   ğŸ“Š æ¬„ä½æª”æ¡ˆ:")
        print(f"      é æœŸ: {results['fields_expected']} å€‹")
        print(f"      æ‰¾åˆ°: {results['fields_found']} å€‹")
        
        if results["fields_missing"]:
            print(f"      âŒ ç¼ºå°‘: {results['fields_missing']}")
        else:
            print(f"      âœ… å…¨éƒ¨å­˜åœ¨")
        
        print(f"\n   ğŸ“ åˆ†é¡çµ±è¨ˆ:")
        for cat, stats in results["by_category"].items():
            status = "âœ…" if stats["found"] == stats["expected"] else "âš ï¸"
            print(f"      {status} {cat}: {stats['found']}/{stats['expected']}")
        
        print(f"\n   ğŸ‘¥ è‚¡ç¥¨æ•¸: {results['tickers_expected']} å®¶")
        
        self.results["completeness"] = results
        return results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. è³‡æ–™å“è³ªæª¢æŸ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def check_quality(self) -> dict:
        """æª¢æŸ¥è³‡æ–™å“è³ª"""
        print("\n" + "=" * 70)
        print("2ï¸âƒ£  è³‡æ–™å“è³ªæª¢æŸ¥ (Data Quality)")
        print("=" * 70)
        
        results = {
            "by_field": {},
            "summary": {
                "total_fields": 0,
                "high_quality": 0,  # ç¼ºå€¼ < 10%
                "medium_quality": 0,  # ç¼ºå€¼ 10-30%
                "low_quality": 0,  # ç¼ºå€¼ > 30%
            }
        }
        
        # æŠ½æ¨£æª¢æŸ¥é—œéµæ¬„ä½
        key_fields = [
            "close", "volume", "pe", "pb", "div_yield",
            "tej_gpm", "tej_opm", "net_income",
            "ocf", "total_assets",
            "qfii_net", "fund_net",
            "monthly_rev_yoy"
        ]
        
        print(f"\n   ğŸ“Š æ¬„ä½å“è³ªåˆ†æ:")
        print(f"   {'æ¬„ä½':<20} {'Shape':<15} {'ç¼ºå€¼%':<10} {'é›¶å€¼%':<10} {'ç‹€æ…‹':<10}")
        print("   " + "-" * 65)
        
        for field in key_fields:
            if field not in self.field_map:
                continue
            
            try:
                df = self._load_field(field)
                
                total_cells = df.size
                null_count = df.isnull().sum().sum()
                zero_count = (df == 0).sum().sum()
                
                null_pct = null_count / total_cells * 100 if total_cells > 0 else 0
                zero_pct = zero_count / total_cells * 100 if total_cells > 0 else 0
                
                # åˆ¤æ–·å“è³ª
                if null_pct < 10:
                    status = "âœ… å„ª"
                    results["summary"]["high_quality"] += 1
                elif null_pct < 30:
                    status = "âš ï¸ ä¸­"
                    results["summary"]["medium_quality"] += 1
                else:
                    status = "âŒ å·®"
                    results["summary"]["low_quality"] += 1
                
                results["summary"]["total_fields"] += 1
                
                results["by_field"][field] = {
                    "shape": df.shape,
                    "null_pct": round(null_pct, 2),
                    "zero_pct": round(zero_pct, 2),
                    "status": status
                }
                
                shape_str = f"{df.shape[0]}Ã—{df.shape[1]}"
                print(f"   {field:<20} {shape_str:<15} {null_pct:>6.1f}%    {zero_pct:>6.1f}%    {status}")
                
            except Exception as e:
                print(f"   {field:<20} âŒ è¼‰å…¥å¤±æ•—: {e}")
        
        # å“è³ªæ‘˜è¦
        s = results["summary"]
        print(f"\n   ğŸ“ˆ å“è³ªæ‘˜è¦:")
        print(f"      å„ª (ç¼ºå€¼<10%): {s['high_quality']}/{s['total_fields']}")
        print(f"      ä¸­ (ç¼ºå€¼10-30%): {s['medium_quality']}/{s['total_fields']}")
        print(f"      å·® (ç¼ºå€¼>30%): {s['low_quality']}/{s['total_fields']}")
        
        self.results["quality"] = results
        return results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. æ•¸å€¼æ­£ç¢ºæ€§æª¢æŸ¥ (èˆ‡åŸå§‹è³‡æ–™æ¯”å°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def check_accuracy(self, sample_tickers: List[str] = None) -> dict:
        """æª¢æŸ¥æ•¸å€¼æ­£ç¢ºæ€§"""
        print("\n" + "=" * 70)
        print("3ï¸âƒ£  æ•¸å€¼æ­£ç¢ºæ€§æª¢æŸ¥ (Accuracy vs Source)")
        print("=" * 70)
        
        # æŠ½æ¨£è‚¡ç¥¨
        if sample_tickers is None:
            all_tickers = self.tickers_info.get("tickers", [])
            # æŠ½æ¨£ 5 æª”: å¤§å‹è‚¡ + ä¸­å‹è‚¡ + å°å‹è‚¡
            sample_tickers = ["2330", "2317", "2882", "1101", "2308"]
            sample_tickers = [t for t in sample_tickers if t in all_tickers][:5]
        
        results = {
            "sample_tickers": sample_tickers,
            "comparisons": {},
            "mismatches": []
        }
        
        print(f"\n   ğŸ” æŠ½æ¨£æ¯”å°: {sample_tickers}")
        
        # æ¯”å°æ¬„ä½å®šç¾©
        field_source_map = {
            "close": ("price", "Close"),
            "open": ("price", "Open"),
            "volume": ("price", "Volume"),
            "pe": ("price", "per"),
            "pb": ("price", "pbr"),
            "tej_gpm": ("financials", "TEJ_GPM"),
            "tej_opm": ("financials", "TEJ_OPM"),
            "qfii_net": ("chip", "qfii_ex"),
            "monthly_rev_yoy": ("monthly_sales", "d0003"),
        }
        
        for ticker in sample_tickers:
            print(f"\n   ğŸ“Š {ticker}:")
            source_data = self._load_source(ticker)
            
            if not source_data:
                print(f"      âš ï¸ æ‰¾ä¸åˆ°åŸå§‹è³‡æ–™")
                continue
            
            comparisons = {}
            
            for field, (source_type, source_col) in field_source_map.items():
                try:
                    # è¼‰å…¥ FieldDB è³‡æ–™
                    field_df = self._load_field(field)
                    if ticker not in field_df.columns:
                        continue
                    
                    field_values = field_df[ticker].dropna()
                    if len(field_values) == 0:
                        continue
                    
                    # è¼‰å…¥åŸå§‹è³‡æ–™
                    source_raw = source_data.get(source_type)
                    if not source_raw:
                        continue
                    
                    source_df = pd.read_json(StringIO(source_raw), orient='split')
                    
                    # è™•ç†ä¸åŒè³‡æ–™çµæ§‹
                    if source_type in ["financials", "balance_sheet", "cashflow"]:
                        # è²¡å ±è³‡æ–™æ˜¯è½‰ç½®çš„
                        source_df = source_df.T
                    
                    if source_col not in source_df.columns and source_col in source_df.index:
                        source_series = source_df.loc[source_col]
                    elif source_col in source_df.columns:
                        source_series = source_df[source_col]
                    else:
                        continue
                    
                    source_series = pd.to_numeric(source_series, errors='coerce').dropna()
                    
                    # æ¯”è¼ƒæœ€æ–°å€¼
                    field_latest = field_values.iloc[-1]
                    source_latest = source_series.iloc[-1] if len(source_series) > 0 else None
                    
                    if source_latest is not None:
                        # æ•¸å€¼æ¯”å° (å…è¨±å°æ•¸é»èª¤å·®)
                        if pd.notna(field_latest) and pd.notna(source_latest):
                            diff = abs(field_latest - source_latest)
                            rel_diff = diff / abs(source_latest) * 100 if source_latest != 0 else 0
                            
                            match = rel_diff < 1  # 1% èª¤å·®ä»¥å…§
                            
                            comparisons[field] = {
                                "field_value": round(field_latest, 4),
                                "source_value": round(source_latest, 4),
                                "diff_pct": round(rel_diff, 2),
                                "match": match
                            }
                            
                            status = "âœ…" if match else "âŒ"
                            print(f"      {status} {field:<15}: FieldDB={field_latest:>12.2f} | Source={source_latest:>12.2f} | Diff={rel_diff:.2f}%")
                            
                            if not match:
                                results["mismatches"].append({
                                    "ticker": ticker,
                                    "field": field,
                                    "field_value": field_latest,
                                    "source_value": source_latest,
                                    "diff_pct": rel_diff
                                })
                
                except Exception as e:
                    pass
            
            results["comparisons"][ticker] = comparisons
        
        # æ‘˜è¦
        total_comparisons = sum(len(c) for c in results["comparisons"].values())
        mismatch_count = len(results["mismatches"])
        
        print(f"\n   ğŸ“ˆ æ¯”å°æ‘˜è¦:")
        print(f"      ç¸½æ¯”å°æ•¸: {total_comparisons}")
        print(f"      ä¸ç¬¦æ•¸: {mismatch_count}")
        print(f"      æº–ç¢ºç‡: {(total_comparisons - mismatch_count) / total_comparisons * 100:.1f}%" if total_comparisons > 0 else "      æº–ç¢ºç‡: N/A")
        
        self.results["accuracy"] = results
        return results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. ä¸€è‡´æ€§æª¢æŸ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def check_consistency(self) -> dict:
        """æª¢æŸ¥è³‡æ–™ä¸€è‡´æ€§"""
        print("\n" + "=" * 70)
        print("4ï¸âƒ£  ä¸€è‡´æ€§æª¢æŸ¥ (Consistency)")
        print("=" * 70)
        
        results = {
            "checks": [],
            "issues": []
        }
        
        # æª¢æŸ¥ 1: High >= Low
        print("\n   ğŸ” æª¢æŸ¥ 1: High >= Low")
        try:
            high = self._load_field("high")
            low = self._load_field("low")
            
            violations = (high < low).sum().sum()
            total = high.size
            
            if violations == 0:
                print(f"      âœ… é€šé (0 violations)")
            else:
                print(f"      âŒ ç™¼ç¾ {violations} ç­† High < Low")
                results["issues"].append(f"High < Low: {violations} cases")
            
            results["checks"].append({
                "name": "High >= Low",
                "passed": violations == 0,
                "violations": int(violations)
            })
        except Exception as e:
            print(f"      âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        # æª¢æŸ¥ 2: Close åœ¨ High å’Œ Low ä¹‹é–“
        print("\n   ğŸ” æª¢æŸ¥ 2: Low <= Close <= High")
        try:
            close = self._load_field("close")
            high = self._load_field("high")
            low = self._load_field("low")
            
            violations = ((close > high) | (close < low)).sum().sum()
            
            if violations == 0:
                print(f"      âœ… é€šé (0 violations)")
            else:
                print(f"      âš ï¸ ç™¼ç¾ {violations} ç­† Close è¶…å‡ºç¯„åœ")
                results["issues"].append(f"Close out of range: {violations} cases")
            
            results["checks"].append({
                "name": "Low <= Close <= High",
                "passed": violations == 0,
                "violations": int(violations)
            })
        except Exception as e:
            print(f"      âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        # æª¢æŸ¥ 3: Volume >= 0
        print("\n   ğŸ” æª¢æŸ¥ 3: Volume >= 0")
        try:
            volume = self._load_field("volume")
            
            violations = (volume < 0).sum().sum()
            
            if violations == 0:
                print(f"      âœ… é€šé (0 violations)")
            else:
                print(f"      âŒ ç™¼ç¾ {violations} ç­†è² æˆäº¤é‡")
                results["issues"].append(f"Negative volume: {violations} cases")
            
            results["checks"].append({
                "name": "Volume >= 0",
                "passed": violations == 0,
                "violations": int(violations)
            })
        except Exception as e:
            print(f"      âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        # æª¢æŸ¥ 4: PE, PB > 0 (æ’é™¤è² å€¼å…¬å¸)
        print("\n   ğŸ” æª¢æŸ¥ 4: PE, PB åˆç†ç¯„åœ (0 < x < 1000)")
        try:
            pe = self._load_field("pe")
            pb = self._load_field("pb")
            
            pe_extreme = ((pe > 1000) | (pe < 0)).sum().sum()
            pb_extreme = ((pb > 100) | (pb < 0)).sum().sum()
            
            if pe_extreme == 0 and pb_extreme == 0:
                print(f"      âœ… é€šé")
            else:
                if pe_extreme > 0:
                    print(f"      âš ï¸ PE æ¥µç«¯å€¼: {pe_extreme} ç­†")
                if pb_extreme > 0:
                    print(f"      âš ï¸ PB æ¥µç«¯å€¼: {pb_extreme} ç­†")
            
            results["checks"].append({
                "name": "PE/PB reasonable range",
                "passed": pe_extreme == 0 and pb_extreme == 0,
                "pe_extreme": int(pe_extreme),
                "pb_extreme": int(pb_extreme)
            })
        except Exception as e:
            print(f"      âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        # æª¢æŸ¥ 5: æ¯›åˆ©ç‡ GPM åˆç†ç¯„åœ (0-100%)
        print("\n   ğŸ” æª¢æŸ¥ 5: æ¯›åˆ©ç‡ GPM åˆç†ç¯„åœ (0-100%)")
        try:
            gpm = self._load_field("tej_gpm")
            
            violations = ((gpm > 100) | (gpm < -50)).sum().sum()
            
            if violations == 0:
                print(f"      âœ… é€šé")
            else:
                print(f"      âš ï¸ GPM æ¥µç«¯å€¼: {violations} ç­†")
            
            results["checks"].append({
                "name": "GPM reasonable range",
                "passed": violations == 0,
                "violations": int(violations)
            })
        except Exception as e:
            print(f"      âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        # æ‘˜è¦
        passed = sum(1 for c in results["checks"] if c["passed"])
        total = len(results["checks"])
        
        print(f"\n   ğŸ“ˆ ä¸€è‡´æ€§æ‘˜è¦:")
        print(f"      é€šé: {passed}/{total}")
        
        self.results["consistency"] = results
        return results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. æ™‚é–“ç¯„åœæª¢æŸ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def check_date_ranges(self) -> dict:
        """æª¢æŸ¥æ™‚é–“ç¯„åœ"""
        print("\n" + "=" * 70)
        print("5ï¸âƒ£  æ™‚é–“ç¯„åœæª¢æŸ¥ (Date Ranges)")
        print("=" * 70)
        
        results = {"by_category": {}}
        
        categories = ["price", "financials", "chip", "monthly_sales"]
        sample_fields = {
            "price": "close",
            "financials": "tej_gpm",
            "chip": "qfii_net",
            "monthly_sales": "monthly_rev_yoy"
        }
        
        print(f"\n   {'é¡åˆ¥':<15} {'æ¬„ä½':<20} {'èµ·å§‹æ—¥æœŸ':<12} {'çµæŸæ—¥æœŸ':<12} {'è³‡æ–™é»æ•¸':<10}")
        print("   " + "-" * 70)
        
        for cat, field in sample_fields.items():
            try:
                df = self._load_field(field)
                
                start_date = str(df.index.min())[:10]
                end_date = str(df.index.max())[:10]
                rows = len(df)
                
                results["by_category"][cat] = {
                    "field": field,
                    "start_date": start_date,
                    "end_date": end_date,
                    "rows": rows
                }
                
                print(f"   {cat:<15} {field:<20} {start_date:<12} {end_date:<12} {rows:<10}")
                
            except Exception as e:
                print(f"   {cat:<15} âš ï¸ ç„¡æ³•æª¢æŸ¥: {e}")
        
        self.results["date_ranges"] = results
        return results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. ç¶œåˆå ±å‘Š
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def run_full_validation(self) -> dict:
        """åŸ·è¡Œå®Œæ•´é©—è­‰"""
        print("\n" + "ğŸ”" * 35)
        print("   Field Database Validator - å®Œæ•´é©—è­‰å ±å‘Š")
        print("ğŸ”" * 35)
        print(f"\n   æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   è³‡æ–™åº«: {self.field_db_path}")
        
        # åŸ·è¡Œæ‰€æœ‰æª¢æŸ¥
        self.check_completeness()
        self.check_quality()
        self.check_accuracy()
        self.check_consistency()
        self.check_date_ranges()
        
        # ç¶œåˆè©•åˆ†
        self._print_summary()
        
        return self.results
    
    def _print_summary(self):
        """å°å‡ºç¶œåˆæ‘˜è¦"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ç¶œåˆé©—è­‰çµæœ")
        print("=" * 70)
        
        # è¨ˆç®—æ•´é«”è©•åˆ†
        scores = []
        
        # å®Œæ•´æ€§å¾—åˆ†
        comp = self.results.get("completeness", {})
        if comp.get("fields_expected", 0) > 0:
            comp_score = comp.get("fields_found", 0) / comp.get("fields_expected", 1) * 100
            scores.append(("å®Œæ•´æ€§", comp_score))
        
        # å“è³ªå¾—åˆ†
        qual = self.results.get("quality", {}).get("summary", {})
        if qual.get("total_fields", 0) > 0:
            qual_score = qual.get("high_quality", 0) / qual.get("total_fields", 1) * 100
            scores.append(("è³‡æ–™å“è³ª", qual_score))
        
        # æº–ç¢ºæ€§å¾—åˆ†
        acc = self.results.get("accuracy", {})
        total_comp = sum(len(c) for c in acc.get("comparisons", {}).values())
        if total_comp > 0:
            acc_score = (total_comp - len(acc.get("mismatches", []))) / total_comp * 100
            scores.append(("æº–ç¢ºæ€§", acc_score))
        
        # ä¸€è‡´æ€§å¾—åˆ†
        cons = self.results.get("consistency", {})
        checks = cons.get("checks", [])
        if checks:
            cons_score = sum(1 for c in checks if c["passed"]) / len(checks) * 100
            scores.append(("ä¸€è‡´æ€§", cons_score))
        
        # è¼¸å‡º
        print("\n   å„é …è©•åˆ†:")
        total_score = 0
        for name, score in scores:
            status = "âœ…" if score >= 90 else "âš ï¸" if score >= 70 else "âŒ"
            print(f"      {status} {name}: {score:.1f}%")
            total_score += score
        
        avg_score = total_score / len(scores) if scores else 0
        
        print(f"\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        overall_status = "âœ… é€šé" if avg_score >= 90 else "âš ï¸ éœ€æ³¨æ„" if avg_score >= 70 else "âŒ éœ€ä¿®å¾©"
        print(f"   ğŸ† ç¶œåˆè©•åˆ†: {avg_score:.1f}% ({overall_status})")
        
        # å»ºè­°
        print("\n   ğŸ’¡ å»ºè­°:")
        if avg_score >= 95:
            print("      è³‡æ–™åº«ç‹€æ…‹æ¥µä½³ï¼Œå¯ä»¥æ”¾å¿ƒä½¿ç”¨ï¼")
        elif avg_score >= 90:
            print("      è³‡æ–™åº«ç‹€æ…‹è‰¯å¥½ï¼Œå°‘æ•¸ç¼ºå€¼å±¬æ­£å¸¸ç¾è±¡ã€‚")
        elif avg_score >= 80:
            print("      éƒ¨åˆ†æ¬„ä½å­˜åœ¨ç¼ºå€¼ï¼Œå»ºè­°äº†è§£åŸå› ã€‚")
        else:
            print("      å»ºè­°æª¢æŸ¥è³‡æ–™ä¾†æºä¸¦é‡æ–°å»ºæ§‹è³‡æ–™åº«ã€‚")


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Field Database Validator")
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿé©—è­‰ (è·³éæº–ç¢ºæ€§æ¯”å°)')
    parser.add_argument('--tickers', type=str, help='æŒ‡å®šé©—è­‰è‚¡ç¥¨ (é€—è™Ÿåˆ†éš”)')
    
    args = parser.parse_args()
    
    validator = FieldDatabaseValidator()
    
    if args.quick:
        # å¿«é€Ÿé©—è­‰
        validator.check_completeness()
        validator.check_quality()
        validator.check_consistency()
    else:
        # å®Œæ•´é©—è­‰
        if args.tickers:
            sample_tickers = args.tickers.split(',')
            validator.check_completeness()
            validator.check_quality()
            validator.check_accuracy(sample_tickers)
            validator.check_consistency()
            validator.check_date_ranges()
            validator._print_summary()
        else:
            validator.run_full_validation()


if __name__ == "__main__":
    main()
