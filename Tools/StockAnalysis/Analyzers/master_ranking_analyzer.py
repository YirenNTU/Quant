#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Master Ranking Analyzer v2.0 - ç¶œåˆæ’ååˆ†æå™¨ï¼ˆçµ‚æ¥µç‰ˆï¼‰
=========================================================
æ•´åˆ Stock_Pool æ‰€æœ‰æ•¸æ“šæºï¼Œé‹ç”¨å…­å¤§å› å­æ¡†æ¶é€²è¡Œé‡åŒ–è©•åˆ†

ã€å› å­æ¬Šé‡é…ç½®ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å› å­             â”‚ æ¬Šé‡     â”‚ æ ¸å¿ƒé‚è¼¯                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å‹•èƒ½ Momentum    â”‚ 20%      â”‚ 12-1æœˆå‹•èƒ½ã€RSç›¸å°å¼·åº¦ã€è¶¨å‹¢ç‹€æ…‹ â”‚
â”‚ å“è³ª Quality     â”‚ 25%      â”‚ Sloanã€F-Scoreã€CCRã€å¥åº·è©•ç´š     â”‚
â”‚ çµæ§‹ Structural  â”‚ 18%      â”‚ GPM/OPMæ‹é»ã€ç‡Ÿé‹æ§“æ¡¿ã€ç‡Ÿæ”¶åŠ é€Ÿ   â”‚
â”‚ ä¼°å€¼ Valuation   â”‚ 17%      â”‚ PE/PB/PSRç™¾åˆ†ä½ã€FCFæ®–åˆ©ç‡        â”‚
â”‚ ç±Œç¢¼ Chip        â”‚ 12%      â”‚ å¤–è³‡/æŠ•ä¿¡ã€èè³‡èåˆ¸ã€ç±Œç¢¼è¶¨å‹¢     â”‚
â”‚ ç­–ç•¥ Strategy    â”‚ 8%       â”‚ Alpha/Early Bird/Contrarian/Gem  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Author: Investment AI System
Version: 2.0 (Final)
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import warnings
import argparse
warnings.filterwarnings('ignore')


class MasterRankingAnalyzer:
    """
    ç¶œåˆæ’ååˆ†æå™¨ v2.0
    
    æ•´åˆæ‰€æœ‰ Stock_Pool æ•¸æ“šæºï¼Œé‹ç”¨æ©Ÿæ§‹ç´šé‡åŒ–æ¡†æ¶é€²è¡Œè©•åˆ†æ’å
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€æ¬Šé‡é…ç½®ã€‘- å¯ä¾å¸‚å ´ç’°å¢ƒèª¿æ•´
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # è¿½æ¼²å‹ç­–ç•¥ (é©åˆç‰›å¸‚åˆæœŸ)
    WEIGHTS_MOMENTUM_CHASING = {
        'momentum': 0.20,      # å‹•èƒ½å› å­ - è¿½æ¼²è¶¨å‹¢
        'quality': 0.25,       # è²¡å‹™å“è³ª - æ ¸å¿ƒé˜²ç¦¦
        'structural': 0.18,    # çµæ§‹è®ŠåŒ– - ç›ˆåˆ©æ‹é»
        'valuation': 0.17,     # ä¼°å€¼å› å­ - å®‰å…¨é‚Šéš›
        'chip': 0.12,          # ç±Œç¢¼å› å­ - è³‡é‡‘å‹•å‘
        'strategy': 0.08,      # ç­–ç•¥åŠ æˆ - ä¿¡è™Ÿç¢ºèª
    }
    
    # çˆ†ç™¼å‰ä½ˆå±€ç­–ç•¥ (é©åˆæ‰¾å°‹æ½›åŠ›è‚¡) â­ æ–°å¢
    WEIGHTS_PRE_BREAKOUT = {
        'momentum': 0.08,      # é™ä½ - é¿å…è¿½é«˜å·²æ¼²è‚¡ç¥¨
        'quality': 0.18,       # ç¶­æŒ - åŸºæœ¬é¢å“è³ª
        'structural': 0.25,    # æé«˜ - æ‹é»ä¿¡è™Ÿæœ€é‡è¦ (ç›ˆåˆ©æ”¹å–„=æœªä¾†å‹•èƒ½)
        'valuation': 0.22,     # æé«˜ - ä½ä¼°æ˜¯å®‰å…¨é‚Šéš›
        'chip': 0.20,          # æé«˜ - ç±Œç¢¼ä½ˆå±€æ˜¯é—œéµä¿¡è™Ÿ
        'strategy': 0.07,      # ç•¥é™
    }
    
    # é è¨­ä½¿ç”¨ï¼šçˆ†ç™¼å‰ä½ˆå±€ç­–ç•¥
    WEIGHTS = WEIGHTS_PRE_BREAKOUT
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€åˆ†æ•¸æ˜ å°„è¡¨ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # å¥åº·è©•ç´šåˆ†æ•¸
    HEALTH_RATING_SCORES = {
        'ğŸ† Sç´šï¼šå„ªè³ªç”Ÿ': 100,
        'â­ Aç´šï¼šè³ªå„ªç”Ÿ': 85,
        'âœ… Bç´šï¼šæ­£å¸¸': 70,
        'âš ï¸ Cç´šï¼šè­¦ç¤º': 45,
        'âš ï¸ Cç´šï¼šè­¦ç¤º (Sloan+CCRé›™æ®º)': 35,
        'ğŸ›‘ Dç´šï¼šé«˜é¢¨éšª': 25,
        'ğŸ›‘ Dç´šï¼šé«˜é¢¨éšª (è²¡å‹™è™›èƒ–)': 20,
        'ğŸš« Fç´šï¼šæ‹’çµ•å¾€ä¾† (è²¡å ±è­¦ç¤º)': 0,
    }
    
    # çµæ§‹è®ŠåŒ–è©•åˆ†
    STRUCTURAL_TAG_SCORES = {
        'ğŸ† SSSç´šï¼šé›™æ‹é»ç¢ºèª': 100,
        'ğŸ”¥ Sç´šï¼šçµæ§‹æ€§æ‹é»': 85,
        'â­ Aç´šï¼šæŒçºŒæ€§æ“´å¼µ': 75,
        'â­ Aç´šï¼šè½‰å‹åˆæœŸ': 68,
        'âœ… Bç´šï¼šè¶¨å‹¢æ”¹å–„': 55,
        'â¡ï¸ Cç´šï¼šè§€æœ›': 40,
    }
    
    # ä¼°å€¼æ±ºç­–è©•åˆ†
    DECISION_SCORES = {
        'ğŸ”¥ Strong Buy': 100,
        'ğŸ“ˆ Accumulate': 82,
        'âœ… Hold': 60,
        'â¡ï¸ Hold': 55,
        'âš ï¸ Hold (Caution)': 45,
        'ğŸ“‰ Trim': 25,
        'ğŸ›‘ Sell': 10,
    }
    
    # Forensic è©•ç´š
    FORENSIC_VERDICT_SCORES = {
        'ğŸ† AAAï¼šè²¡å‹™é€æ˜å„ªè³ª': 100,
        'â­ AAï¼šè²¡å‹™å¥åº·': 85,
        'âœ… Aï¼šè²¡å‹™æ­£å¸¸': 70,
        'âš ï¸ Bï¼šéœ€ç•™æ„': 50,
        'ğŸ›‘ Cï¼šé«˜é¢¨éšª': 25,
    }
    
    # Gem é¡å‹åˆ†æ•¸
    GEM_TYPE_SCORES = {
        'ğŸ’ğŸ’ğŸ’ SSSç´šéš±è—å¯¶çŸ³': 100,
        'ğŸ’ğŸ’ Sç´šéš±è—å¯¶çŸ³': 80,
        'ğŸ’ Aç´šéš±è—å¯¶çŸ³': 60,
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€åˆå§‹åŒ–ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def __init__(self, stock_pool_path: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            stock_pool_path: Stock_Pool è³‡æ–™å¤¾è·¯å¾‘ï¼ŒNone å‰‡è‡ªå‹•åµæ¸¬
        """
        if stock_pool_path is None:
            current_file = Path(__file__).resolve()
            self.stock_pool_path = current_file.parent.parent.parent.parent / "Stock_Pool"
        else:
            self.stock_pool_path = Path(stock_pool_path)
        
        self.data = {}                  # æ‰€æœ‰æ•¸æ“šæº
        self.stock_names = {}           # è‚¡ç¥¨åç¨±å°ç…§
        self.final_ranking = None       # æœ€çµ‚æ’åçµæœ
        self.merged_df = None           # åˆä½µå¾Œçš„å®Œæ•´æ•¸æ“š
        self.stats = {}                 # çµ±è¨ˆè³‡è¨Š
        
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€æ•¸æ“šè¼‰å…¥ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def load_all_data(self) -> dict:
        """è¼‰å…¥æ‰€æœ‰åˆ†æå ±å‘Š"""
        print("=" * 70)
        print("ğŸ“Š è¼‰å…¥æ‰€æœ‰ Stock_Pool æ•¸æ“šæº...")
        print("=" * 70)
        
        # å®šç¾©æ‰€æœ‰æ•¸æ“šæº
        files_to_load = {
            # ä¸»æ•¸æ“šæº
            'cross_factor': 'cross_factor_full_analysis.csv',
            'factor_v3': 'factor_analysis_v3.csv',
            
            # å¥åº·èˆ‡å“è³ª
            'health': 'final_health_check_report_v2.csv',
            'forensic': 'institutional_forensic_report_v2.csv',
            'hidden_gems_forensic': 'hidden_gems_forensic_report_v2.csv',
            'hidden_gems_health': 'hidden_gems_health_check_report_v2.csv',
            
            # çµæ§‹èˆ‡ä¼°å€¼
            'structural': 'structural_change_report_v2.csv',
            'structural_full': 'structural_change_report_v2_full.csv',
            'valuation': 'final_valuation_report_v2.csv',
            'hidden_gems_valuation': 'hidden_gems_valuation_report_v2.csv',
            
            # éš±è—å¯¶çŸ³
            'hidden_gems': 'hidden_gems_report_v2.csv',
            
            # ç­–ç•¥ä¿¡è™Ÿ
            'alpha': 'alpha_stocks.csv',
            'alpha_top20': 'alpha_hunter_top20.csv',
            'early_bird': 'early_bird_stocks.csv',
            'contrarian': 'contrarian_stocks.csv',
        }
        
        loaded_count = 0
        for key, filename in files_to_load.items():
            filepath = self.stock_pool_path / filename
            if filepath.exists():
                try:
                    df = pd.read_csv(filepath)
                    self.data[key] = df
                    print(f"  âœ… {filename:<45} {len(df):>4} ç­†")
                    loaded_count += 1
                except Exception as e:
                    print(f"  âš ï¸ {filename}: è¼‰å…¥å¤±æ•— - {e}")
            else:
                print(f"  âš ï¸ {filename}: æª”æ¡ˆä¸å­˜åœ¨")
        
        # è¼‰å…¥è‚¡ç¥¨åç¨±å°ç…§è¡¨
        list_path = self.stock_pool_path / "list.json"
        if list_path.exists():
            with open(list_path, 'r', encoding='utf-8') as f:
                self.stock_names = json.load(f)
            print(f"  âœ… {'list.json':<45} {len(self.stock_names):>4} æª”è‚¡ç¥¨")
        
        print(f"\nğŸ“ æˆåŠŸè¼‰å…¥ {loaded_count} å€‹æ•¸æ“šæº")
        return self.data
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€æ•¸æ“šåˆä½µã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def merge_all_data(self) -> pd.DataFrame:
        """åˆä½µæ‰€æœ‰æ•¸æ“šæºç‚ºå–®ä¸€ DataFrame"""
        print("\nğŸ”„ åˆä½µæ‰€æœ‰æ•¸æ“š...")
        
        if 'cross_factor' not in self.data:
            raise ValueError("âŒ ç¼ºå°‘æ ¸å¿ƒæ•¸æ“š: cross_factor_full_analysis.csv")
        
        # ä»¥ cross_factor ç‚ºåŸºç¤
        df = self.data['cross_factor'].copy()
        initial_cols = set(df.columns)
        
        # 1. åˆä½µå®Œæ•´çµæ§‹æ•¸æ“šï¼ˆå–å¾—æ›´å¤šç´°ç¯€ï¼‰
        if 'structural_full' in self.data:
            struct_cols = ['Ticker', 'GPM_YoY_Slope', 'GPM_Consecutive', 
                          'OPM_YoY_Slope', 'OPM_Consecutive', 'Non_Op_Ratio', 'Score_Percentile']
            # éæ¿¾å‡ºå­˜åœ¨çš„æ¬„ä½
            available_cols = [c for c in struct_cols if c in self.data['structural_full'].columns]
            if available_cols:
                struct_df = self.data['structural_full'][available_cols].copy()
                df = df.merge(struct_df, on='Ticker', how='left', suffixes=('', '_struct_full'))
        
        # 2. åˆä½µ Factor V3 ç´°ç¯€åˆ†æ•¸
        if 'factor_v3' in self.data:
            factor_cols = ['Ticker', 'FCF_Yield_Status', 'Stability_Status', 
                          'Asset_Growth_Status', 'Drawdown_Status']
            available_cols = [c for c in factor_cols if c in self.data['factor_v3'].columns]
            if available_cols:
                factor_df = self.data['factor_v3'][available_cols].copy()
                df = df.merge(factor_df, on='Ticker', how='left', suffixes=('', '_factor'))
        
        # 3. åˆä½µ Forensic æ•¸æ“šï¼ˆå„ªå…ˆä½¿ç”¨æ©Ÿæ§‹ç‰ˆï¼‰
        if 'forensic' in self.data:
            forensic_cols = ['Ticker', 'Forensic_Score', 'Forensic_Verdict', 
                            'Hollow_Ratio', 'Quality_Warning', 'ROIC', 'Warnings']
            available_cols = [c for c in forensic_cols if c in self.data['forensic'].columns]
            if available_cols:
                forensic_df = self.data['forensic'][available_cols].copy()
                # é‡å‘½åä»¥é¿å…è¡çª
                forensic_df = forensic_df.rename(columns={
                    'Forensic_Score': 'Forensic_Score_Inst',
                    'Forensic_Verdict': 'Forensic_Verdict_Inst'
                })
                df = df.merge(forensic_df, on='Ticker', how='left', suffixes=('', '_forensic'))
        
        # 4. åˆä½µå¥åº·æ•¸æ“šç´°ç¯€
        if 'health' in self.data:
            health_cols = ['Ticker', 'FCF_Value', 'Inv_Days', 'Inv_Days_Change',
                          'Score_V1', 'Result_Tag_V1']
            available_cols = [c for c in health_cols if c in self.data['health'].columns]
            if available_cols:
                health_df = self.data['health'][available_cols].copy()
                df = df.merge(health_df, on='Ticker', how='left', suffixes=('', '_health'))
        
        # 5. åˆä½µéš±è—å¯¶çŸ³ç´°ç¯€
        if 'hidden_gems' in self.data:
            gem_cols = ['Ticker', 'RD_Momentum', 'In_Elite_List']
            available_cols = [c for c in gem_cols if c in self.data['hidden_gems'].columns]
            if available_cols:
                gem_df = self.data['hidden_gems'][available_cols].copy()
                df = df.merge(gem_df, on='Ticker', how='left', suffixes=('', '_gem'))
        
        # 6. æ¨™è¨˜ç­–ç•¥ä¿¡è™Ÿ
        df['Is_Alpha'] = df['Ticker'].isin(self.data.get('alpha', pd.DataFrame()).get('Ticker', []))
        df['Is_EarlyBird'] = df['Ticker'].isin(self.data.get('early_bird', pd.DataFrame()).get('Ticker', []))
        df['Is_Contrarian'] = df['Ticker'].isin(self.data.get('contrarian', pd.DataFrame()).get('Ticker', []))
        df['Is_HiddenGem'] = df['Ticker'].isin(self.data.get('hidden_gems', pd.DataFrame()).get('Ticker', []))
        
        # 7. å–å¾—ç­–ç•¥åˆ†æ•¸
        if 'alpha' in self.data and 'Alpha_Score' in self.data['alpha'].columns:
            alpha_scores = self.data['alpha'][['Ticker', 'Alpha_Score', 'Alpha_Tag']].copy()
            df = df.merge(alpha_scores, on='Ticker', how='left', suffixes=('', '_alpha'))
        
        if 'early_bird' in self.data and 'EarlyBird_Score' in self.data['early_bird'].columns:
            eb_scores = self.data['early_bird'][['Ticker', 'EarlyBird_Score', 'EarlyBird_Tag']].copy()
            df = df.merge(eb_scores, on='Ticker', how='left', suffixes=('', '_eb'))
        
        if 'contrarian' in self.data and 'Contrarian_Score' in self.data['contrarian'].columns:
            con_scores = self.data['contrarian'][['Ticker', 'Contrarian_Score', 'Contrarian_Tag']].copy()
            df = df.merge(con_scores, on='Ticker', how='left', suffixes=('', '_con'))
        
        new_cols = set(df.columns) - initial_cols
        print(f"  âœ… åˆä½µå®Œæˆ: {len(df)} ç­†è³‡æ–™ï¼Œæ–°å¢ {len(new_cols)} å€‹æ¬„ä½")
        
        self.merged_df = df
        return df
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­ä¸€ï¼šå‹•èƒ½å› å­ Momentum (20%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_momentum_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—å‹•èƒ½å› å­åˆ†æ•¸ (Physics-Informed Continuous Scoring)
        
        çµ„æˆ:
        - 12-1æœˆå‹•èƒ½ (40%): Momentum_12_1
        - ç›¸å°å¼·åº¦ (30%): RS_Ratio
        - è¿‘æœŸè¡¨ç¾ (20%): Return_12M, Return_1M
        - å‹•èƒ½ç‹€æ…‹ (10%): Momentum_Status
        
        Refactored: Uses sigmoid functions for continuous, differentiable scoring.
        Eliminates boundary effects from discrete step functions.
        """
        scores = {'momentum_12_1': 50, 'rs_ratio': 50, 'returns': 50, 'status': 50}
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. 12-1æœˆå‹•èƒ½ (æ ¸å¿ƒå‹•èƒ½æŒ‡æ¨™)
        #    Sigmoid parameters calibrated to match original business logic:
        #    - midpoint=25: Neutral zone around +25% (slight positive bias for momentum stocks)
        #    - steepness=0.04: Gradual transition across typical momentum range [-50, 100]
        #    - min_score=5: Floor to avoid zero scores for very negative momentum
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mom_12_1 = self._safe_get(row, 'Momentum_12_1', 0)
        scores['momentum_12_1'] = self._sigmoid_score(
            x=mom_12_1,
            midpoint=25,      # +25% is neutral; aligns with old threshold of ~15-30
            steepness=0.04,   # Moderate transition speed
            min_score=5,      # Floor score for extreme losers
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. RS ç›¸å°å¼·åº¦
        #    Sigmoid centered at RS=1.0 (market-neutral)
        #    - midpoint=1.0: RS=1 means equal to market
        #    - steepness=4.0: Sharper transition since RS typically ranges 0.5-1.5
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rs = self._safe_get(row, 'RS_Ratio', 1.0)
        scores['rs_ratio'] = self._sigmoid_score(
            x=rs,
            midpoint=1.0,     # Market-neutral point
            steepness=4.0,    # Faster transition for tight RS range
            min_score=10,
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3. å ±é…¬è¡¨ç¾ (Composite of 12M and 1M returns)
        #    Using log-transform for large returns to prevent outlier dominance
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ret_12m = self._safe_get(row, 'Return_12M', 0)
        ret_1m = self._safe_get(row, 'Return_1M', 0)
        
        # 12M å ±é…¬: Log-sigmoid hybrid for wide range (-50% to 200%+)
        # Apply signed log transform to compress extreme winners
        ret_12m_transformed = self._signed_log_transform(ret_12m, base_scale=20)
        score_12m = self._sigmoid_score(
            x=ret_12m_transformed,
            midpoint=0.5,     # Corresponds to ~10% return after transform
            steepness=1.2,
            min_score=10,
            max_score=100
        )
        
        # 1M çŸ­æœŸå‹•èƒ½: Narrower range, faster response
        score_1m = self._sigmoid_score(
            x=ret_1m,
            midpoint=3,       # +3% monthly return is neutral
            steepness=0.15,   # Moderate sensitivity
            min_score=20,
            max_score=90      # Capped to reduce short-term noise influence
        )
        
        scores['returns'] = round(score_12m * 0.7 + score_1m * 0.3, 2)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 4. å‹•èƒ½ç‹€æ…‹ (Categorical - kept as lookup with smooth interpolation)
        #    Status tags are categorical; map to scores with slight noise tolerance
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        status = str(row.get('Momentum_Status', ''))
        status_score_map = {
            'æ¥µå¼·': 100, 'ğŸš€': 100,
            'å¼·å‹¢': 80,
            'æ­£å‘': 60,
            'ä¸­æ€§': 50,
            'å¼±å‹¢': 35, 'âš ï¸': 35,
            'æ¥µå¼±': 15, 'ğŸ›‘': 15
        }
        # Find best matching status
        matched_score = 50  # Default neutral
        for key, pts in status_score_map.items():
            if key in status:
                matched_score = pts
                break
        scores['status'] = matched_score
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 5. éç†±æ‡²ç½° (Pre-Breakout Strategy Enhancement)
        #    å¦‚æœè‚¡åƒ¹å·²ç¶“å¤§å¹…æ‹‰å‡ï¼Œçµ¦äºˆæ‡²ç½°ï¼Œå› ç‚ºçˆ†ç™¼åŠ›å·²ç¶“é‡‹æ”¾
        #    - Return_12M > 80%: åš´é‡éç†±
        #    - Return_12M > 50%: ä¸­åº¦éç†±
        #    - RS_Ratio > 1.5: å·²é¡¯è‘—è·‘è´å¤§ç›¤
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        overheat_penalty = 0
        
        # å¹´åº¦å ±é…¬éç†±æª¢æ¸¬
        if ret_12m > 80:
            overheat_penalty += 25  # æ¼²å¹…éå¤§ï¼Œçˆ†ç™¼åŠ›å·²é‡‹æ”¾
        elif ret_12m > 50:
            overheat_penalty += 15  # ä¸­åº¦éç†±
        elif ret_12m > 30:
            overheat_penalty += 5   # è¼•å¾®éç†±
        
        # RS éç†±æª¢æ¸¬
        if rs > 1.8:
            overheat_penalty += 15  # å·²å¤§å¹…è·‘è´å¤§ç›¤
        elif rs > 1.5:
            overheat_penalty += 8   # é¡¯è‘—è·‘è´
        
        # è¿‘æœŸéç†±æª¢æ¸¬ï¼ˆ1å€‹æœˆæ¼²å¤ªå¤š = çŸ­æœŸéç†±ï¼‰
        if ret_1m > 20:
            overheat_penalty += 12  # çŸ­æœŸæš´æ¼²
        elif ret_1m > 15:
            overheat_penalty += 6
        
        scores['overheat_penalty'] = overheat_penalty
        
        # åŠ æ¬Šå½™ç¸½
        raw_final = (scores['momentum_12_1'] * 0.40 +
                    scores['rs_ratio'] * 0.30 +
                    scores['returns'] * 0.20 +
                    scores['status'] * 0.10)
        
        # å¥—ç”¨éç†±æ‡²ç½°
        final = max(5, raw_final - overheat_penalty)
        
        return {'score': round(final, 2), 'details': scores, 'overheat_penalty': overheat_penalty}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­äºŒï¼šå“è³ªå› å­ Quality (25%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_quality_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—è²¡å‹™å“è³ªåˆ†æ•¸ (Physics-Informed Continuous Scoring)
        
        çµ„æˆ:
        - å¥åº·è©•åˆ† (30%): Health_Score (ç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸)
        - Forensic è©•åˆ† (25%): Forensic_Score (ç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸)
        - Sloan æ¯”ç‡ (20%): Sloan_Ratio (ç›ˆé¤˜å“è³ª)
        - F-Score (15%): Piotroski F-Score
        - ç¾é‡‘è¦†è“‹ (10%): CCR_TTM
        
        Refactored: é¿å…å­—ä¸²æ¨™ç±¤è½‰æ›çš„è³‡è¨Šæå¤±ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸ + sigmoid æ˜ å°„
        """
        scores = {'health': 50, 'forensic': 50, 'sloan': 50, 'fscore': 50, 'ccr': 50}
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. å¥åº·è©•åˆ† - ç›´æ¥ä½¿ç”¨ Health_Scoreï¼Œé¿å…æ¨™ç±¤è½‰æ›çš„è³‡è¨Šæå¤±
        #    å¦‚æœæœ‰ Health_Score åŸå§‹åˆ†æ•¸ï¼Œå„ªå…ˆä½¿ç”¨ï¼›å¦å‰‡ fallback åˆ°æ¨™ç±¤æ˜ å°„
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        health_score_raw = self._safe_get(row, 'Health_Score', None)
        
        if health_score_raw is not None:
            # ç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸ï¼Œé€šé sigmoid å¹³æ»‘æ˜ å°„åˆ° 0-100
            # Health_Score é€šå¸¸åœ¨ 30-100 ç¯„åœï¼Œmidpoint=70 å°æ‡‰ã€Œæ­£å¸¸ã€
            scores['health'] = self._sigmoid_score(
                x=health_score_raw,
                midpoint=70,      # 70 åˆ†ç‚ºä¸­æ€§é»
                steepness=0.08,   # å¹³ç·©éæ¸¡
                min_score=10,
                max_score=100
            )
        else:
            # Fallback: å¾å­—ä¸²æ¨™ç±¤æ˜ å°„ï¼ˆå…¼å®¹èˆŠæ•¸æ“šï¼‰
            health_rating = str(row.get('Health_Rating', ''))
            for rating, pts in self.HEALTH_RATING_SCORES.items():
                if rating in health_rating or any(key in health_rating for key in rating.split('ï¼š')):
                    scores['health'] = pts
                    break
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. Forensic è©•åˆ† - ç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸ï¼Œä¸å†é€šé Verdict æ¨™ç±¤
        #    Forensic_Score é€šå¸¸åœ¨ 40-100 ç¯„åœ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        forensic_score_raw = self._safe_get(row, 'Forensic_Score', None)
        forensic_score_inst = self._safe_get(row, 'Forensic_Score_Inst', None)
        
        # å„ªå…ˆä½¿ç”¨æ©Ÿæ§‹ç‰ˆåˆ†æ•¸
        forensic_final = forensic_score_inst if forensic_score_inst is not None else forensic_score_raw
        
        if forensic_final is not None:
            # ç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•¸ï¼Œsigmoid å¹³æ»‘æ˜ å°„
            scores['forensic'] = self._sigmoid_score(
                x=forensic_final,
                midpoint=75,      # 75 åˆ†ç‚ºä¸­æ€§é»ï¼ˆAç´šé–€æª»ï¼‰
                steepness=0.1,
                min_score=15,
                max_score=100
            )
        # ä¸å†ä½¿ç”¨ Forensic_Verdict å­—ä¸²æ¨™ç±¤ï¼ˆé¿å…è³‡è¨Šæå¤±ï¼‰
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3. Sloan Ratio (ç›ˆé¤˜å“è³ªï¼Œè¶Šä½è¶Šå¥½) - Inverted Sigmoid
        #    æ¨™æº–ç¯„åœ: -0.15 (å„ªç§€) ~ +0.20 (å±éšª)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        sloan = self._safe_get(row, 'Sloan_Ratio', 0)
        # æ³¨æ„ï¼šSloan æ˜¯åå‘å› å­ï¼Œè¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥ä½¿ç”¨ -sloan
        scores['sloan'] = self._sigmoid_score(
            x=-sloan,             # å–è² è™Ÿï¼Œä½¿ä½ Sloan å¾—é«˜åˆ†
            midpoint=0,           # Sloan=0 ç‚ºä¸­æ€§é»
            steepness=15,         # åœ¨ Â±0.1 ç¯„åœå…§å¿«é€Ÿéæ¸¡
            min_score=5,
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 4. F-Score (Piotroski) - é›¢æ•£æ•´æ•¸ 0-9ï¼Œä½¿ç”¨ sigmoid å¹³æ»‘åŒ–
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        f_score = self._safe_get(row, 'F_Score', None)
        
        if f_score is not None:
            # F-Score ç¯„åœ 0-9ï¼Œmidpoint=5.5 ç‚ºä¸­æ€§é»
            scores['fscore'] = self._sigmoid_score(
                x=f_score,
                midpoint=5.5,
                steepness=0.8,    # æ¯ 1 åˆ†å·®ç•°ç´„ 15-20 åˆ†è®ŠåŒ–
                min_score=10,
                max_score=100
            )
        else:
            scores['fscore'] = 50  # ç„¡æ•¸æ“šæ™‚çµ¦ä¸­æ€§åˆ†
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 5. ç¾é‡‘è¦†è“‹ç‡ CCR_TTM - Sigmoid é€£çºŒåŒ–
        #    CCR > 1.0 è¡¨ç¤ºç¾é‡‘æµå¤§æ–¼æ·¨åˆ©ï¼ˆå¥åº·ï¼‰
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ccr = self._safe_get(row, 'CCR_TTM', None)
        
        if ccr is not None:
            scores['ccr'] = self._sigmoid_score(
                x=ccr,
                midpoint=1.0,     # CCR=1.0 ç‚ºä¸­æ€§é»
                steepness=3.0,    # åœ¨ 0.5-1.5 ç¯„åœå…§å¹³æ»‘éæ¸¡
                min_score=15,
                max_score=100
            )
        
        # åŠ æ¬Šå½™ç¸½
        final = (scores['health'] * 0.30 +
                scores['forensic'] * 0.25 +
                scores['sloan'] * 0.20 +
                scores['fscore'] * 0.15 +
                scores['ccr'] * 0.10)
        
        return {'score': round(final, 2), 'details': scores}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­ä¸‰ï¼šçµæ§‹å› å­ Structural (18%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_structural_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—çµæ§‹æ€§è®ŠåŒ–åˆ†æ•¸
        
        çµ„æˆ:
        - çµæ§‹è©•ç´š (35%): Result_Tag (SSS/S/A/Bç´š)
        - æ‹é»ç¢ºèª (25%): GPM_Inflection, OPM_Inflection
        - ç‡Ÿé‹æ§“æ¡¿ (20%): Operating_Leverage
        - ç‡Ÿæ”¶å‹•èƒ½ (20%): Rev_YoY, Rev_Acceleration, Rev_New_High
        """
        scores = {'tag': 50, 'inflection': 50, 'leverage': 50, 'revenue': 50}
        
        # 1. çµæ§‹è©•ç´š
        result_tag = str(row.get('Result_Tag', ''))
        for tag, pts in self.STRUCTURAL_TAG_SCORES.items():
            if tag in result_tag or any(key in result_tag for key in ['SSS', 'Sç´š', 'Aç´š', 'Bç´š']):
                if 'SSS' in result_tag:
                    scores['tag'] = 100
                elif 'Sç´š' in result_tag and 'SSS' not in result_tag:
                    scores['tag'] = 85
                elif 'Aç´š' in result_tag:
                    scores['tag'] = 72
                elif 'Bç´š' in result_tag:
                    scores['tag'] = 55
                break
        
        # 2. æ‹é»ç¢ºèª (é‡è¦ä¿¡è™Ÿ)
        gpm_inflection = row.get('GPM_Inflection', False)
        opm_inflection = row.get('OPM_Inflection', False)
        
        if gpm_inflection and opm_inflection:
            scores['inflection'] = 100  # é›™æ‹é»ç¢ºèª
        elif opm_inflection:
            scores['inflection'] = 80   # OPMæ‹é»æ›´é‡è¦
        elif gpm_inflection:
            scores['inflection'] = 70   # GPMæ‹é»
        else:
            scores['inflection'] = 40
        
        # GPM/OPM é€£çºŒæ”¹å–„åŠ æˆ
        gpm_consec = self._safe_get(row, 'GPM_Consecutive', 0)
        opm_consec = self._safe_get(row, 'OPM_Consecutive', 0)
        if gpm_consec >= 2 or opm_consec >= 2:
            scores['inflection'] = min(100, scores['inflection'] + 10)
        
        # 3. ç‡Ÿé‹æ§“æ¡¿
        ol = self._safe_get(row, 'Operating_Leverage', 1.0)
        if ol > 3.0:
            scores['leverage'] = 100  # æ¥µé«˜ç‡Ÿé‹æ§“æ¡¿
        elif ol > 2.0:
            scores['leverage'] = 85
        elif ol > 1.5:
            scores['leverage'] = 75
        elif ol > 1.0:
            scores['leverage'] = 60
        elif ol > 0.5:
            scores['leverage'] = 45
        elif ol > 0:
            scores['leverage'] = 35
        else:
            scores['leverage'] = 20  # è² å‘æ§“æ¡¿
        
        # 4. ç‡Ÿæ”¶å‹•èƒ½
        rev_yoy = self._safe_get(row, 'Rev_YoY', 0)
        rev_acc = self._safe_get(row, 'Rev_Acceleration', 0)
        rev_new_high = row.get('Rev_New_High', False)
        
        # ç‡Ÿæ”¶å¹´å¢ç‡
        if rev_yoy > 30:
            rev_score = 100
        elif rev_yoy > 20:
            rev_score = 85
        elif rev_yoy > 10:
            rev_score = 70
        elif rev_yoy > 5:
            rev_score = 60
        elif rev_yoy > 0:
            rev_score = 50
        elif rev_yoy > -10:
            rev_score = 35
        else:
            rev_score = 20
        
        # ç‡Ÿæ”¶åŠ é€Ÿåº¦åŠ æˆ
        if rev_acc > 0:
            rev_score = min(100, rev_score + 10)
        
        # ç‡Ÿæ”¶å‰µé«˜åŠ æˆ
        if rev_new_high:
            rev_score = min(100, rev_score + 10)
        
        scores['revenue'] = rev_score
        
        # åŠ æ¬Šå½™ç¸½
        final = (scores['tag'] * 0.35 +
                scores['inflection'] * 0.25 +
                scores['leverage'] * 0.20 +
                scores['revenue'] * 0.20)
        
        return {'score': round(final, 2), 'details': scores}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­å››ï¼šä¼°å€¼å› å­ Valuation (17%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_valuation_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—ä¼°å€¼å› å­åˆ†æ•¸ (è¶Šä¾¿å®œè¶Šé«˜åˆ†)
        
        çµ„æˆ:
        - PE ç™¾åˆ†ä½ (30%): PE_Percentile (æ­·å²ç›¸å°ä¼°å€¼)
        - PB ç™¾åˆ†ä½ (25%): PB_Percentile
        - PSR ç™¾åˆ†ä½ (15%): PSR_Percentile
        - FCF æ®–åˆ©ç‡ (15%): FCF_Yield
        - è²·è³£æ±ºç­– (15%): Decision
        """
        scores = {'pe': 50, 'pb': 50, 'psr': 50, 'fcf': 50, 'decision': 50}
        
        # 1. PE ç™¾åˆ†ä½ (è¶Šä½è¶Šä¾¿å®œ)
        pe_pct = self._safe_get(row, 'PE_Percentile', 50)
        if pe_pct < 10:
            scores['pe'] = 100  # æ¥µåº¦ä½ä¼°
        elif pe_pct < 25:
            scores['pe'] = 85
        elif pe_pct < 40:
            scores['pe'] = 70
        elif pe_pct < 60:
            scores['pe'] = 55
        elif pe_pct < 75:
            scores['pe'] = 40
        elif pe_pct < 90:
            scores['pe'] = 25
        else:
            scores['pe'] = 10  # æ¥µåº¦é«˜ä¼°
        
        # 2. PB ç™¾åˆ†ä½
        pb_pct = self._safe_get(row, 'PB_Percentile', 50)
        if pb_pct < 10:
            scores['pb'] = 100
        elif pb_pct < 25:
            scores['pb'] = 85
        elif pb_pct < 40:
            scores['pb'] = 70
        elif pb_pct < 60:
            scores['pb'] = 55
        elif pb_pct < 75:
            scores['pb'] = 40
        else:
            scores['pb'] = 25
        
        # 3. PSR ç™¾åˆ†ä½
        psr_pct = self._safe_get(row, 'PSR_Percentile', 50)
        if psr_pct < 20:
            scores['psr'] = 90
        elif psr_pct < 40:
            scores['psr'] = 70
        elif psr_pct < 60:
            scores['psr'] = 55
        elif psr_pct < 80:
            scores['psr'] = 40
        else:
            scores['psr'] = 25
        
        # 4. FCF æ®–åˆ©ç‡ (è¶Šé«˜è¶Šæœ‰åƒ¹å€¼)
        fcf_yield = self._safe_get(row, 'FCF_Yield', 0)
        if fcf_yield > 0.10:
            scores['fcf'] = 100
        elif fcf_yield > 0.07:
            scores['fcf'] = 85
        elif fcf_yield > 0.05:
            scores['fcf'] = 72
        elif fcf_yield > 0.03:
            scores['fcf'] = 60
        elif fcf_yield > 0.01:
            scores['fcf'] = 48
        elif fcf_yield > 0:
            scores['fcf'] = 35
        else:
            scores['fcf'] = 20  # è² FCF
        
        # 5. è²·è³£æ±ºç­–
        decision = str(row.get('Decision', ''))
        for dec, pts in self.DECISION_SCORES.items():
            if dec in decision:
                scores['decision'] = pts
                break
        
        # åŠ æ¬Šå½™ç¸½
        final = (scores['pe'] * 0.30 +
                scores['pb'] * 0.25 +
                scores['psr'] * 0.15 +
                scores['fcf'] * 0.15 +
                scores['decision'] * 0.15)
        
        return {'score': round(final, 2), 'details': scores}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­äº”ï¼šç±Œç¢¼å› å­ Chip (12%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_chip_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—ç±Œç¢¼å› å­åˆ†æ•¸ (Physics-Informed Continuous Scoring)
        
        çµ„æˆ:
        - å¤–è³‡å‹•å‘ (35%): QFII_Net_4W
        - æŠ•ä¿¡å‹•å‘ (25%): Fund_Net_4W
        - ç±Œç¢¼è¶¨å‹¢ (25%): Chip_Trend
        - èè³‡èåˆ¸ (15%): Margin_Score, Margin_Sentiment
        
        Refactored: Uses signed log-transform + sigmoid to eliminate:
        1. Size Bias: Log compression makes scoring market-cap neutral
        2. Boundary Effects: Sigmoid provides smooth, differentiable transitions
        
        Design Rationale:
        - Raw QFII/Fund values span huge ranges (e.g., -500K to +1M shares)
        - Large-cap stocks naturally have higher absolute flows â†’ unfair advantage
        - Solution: Apply log-transform to compress scale, then sigmoid for scoring
        """
        scores = {'qfii': 50, 'fund': 50, 'trend': 50, 'margin': 50}
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. å¤–è³‡å‹•å‘ (4é€±æ·¨è²·è¶…) - Log-Sigmoid Hybrid
        #    
        #    Pipeline: Raw QFII â†’ Signed Log Transform â†’ Sigmoid Score
        #    
        #    Log transform parameters:
        #    - base_scale=5000: Normalizes so typical institutional flows (~5K) â†’ ~1.0
        #    
        #    Sigmoid parameters:
        #    - midpoint=0.5: Slight positive bias (net buying is bullish signal)
        #    - steepness=0.8: Moderate transition for log-transformed range
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        qfii_raw = self._safe_get(row, 'QFII_Net_4W', 0)
        qfii_transformed = self._signed_log_transform(qfii_raw, base_scale=5000)
        scores['qfii'] = self._sigmoid_score(
            x=qfii_transformed,
            midpoint=0.5,     # Slight bullish bias
            steepness=0.8,    # Moderate transition in log-space
            min_score=10,     # Floor for heavy selling
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. æŠ•ä¿¡å‹•å‘ (4é€±æ·¨è²·è¶…)
        #    Smaller scale than QFII; adjust base_scale accordingly
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        fund_raw = self._safe_get(row, 'Fund_Net_4W', 0)
        fund_transformed = self._signed_log_transform(fund_raw, base_scale=1000)
        scores['fund'] = self._sigmoid_score(
            x=fund_transformed,
            midpoint=0.3,     # Trust fund buying signal slightly
            steepness=0.9,
            min_score=10,
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3. ç±Œç¢¼è¶¨å‹¢ (Categorical with ordinal encoding)
        #    Map categorical trends to ordinal scale, then apply sigmoid
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        chip_trend = str(row.get('Chip_Trend', ''))
        
        # Ordinal encoding for trend categories
        trend_ordinal = 0  # Neutral baseline
        if 'é›™å¤š' in chip_trend:
            trend_ordinal = 3       # Best: Both QFII and Fund buying
        elif 'å¤–è³‡' in chip_trend and 'è²·è¶…' in chip_trend:
            trend_ordinal = 2       # Good: QFII buying
        elif 'æŠ•ä¿¡' in chip_trend and 'è²·è¶…' in chip_trend:
            trend_ordinal = 1.5     # Good: Fund buying
        elif 'è³£è¶…' in chip_trend and 'é›™ç©º' not in chip_trend:
            trend_ordinal = -1      # Mild selling
        elif 'é›™ç©º' in chip_trend:
            trend_ordinal = -2      # Worst: Both selling
        
        # Apply sigmoid to ordinal value
        scores['trend'] = self._sigmoid_score(
            x=trend_ordinal,
            midpoint=0.5,     # Slight positive bias
            steepness=1.5,    # Moderate transition for discrete ordinals
            min_score=15,
            max_score=100
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 4. èè³‡èåˆ¸æƒ…ç·’ (Composite sigmoid)
        #    Base score + sentiment adjustments via additive sigmoid boosts
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        margin_score_raw = self._safe_get(row, 'Margin_Score', 50)
        margin_sentiment = str(row.get('Margin_Sentiment', ''))
        
        # Normalize raw margin score to sigmoid (already 0-100, just smooth it)
        base_margin = self._sigmoid_score(
            x=margin_score_raw,
            midpoint=50,      # Center at 50
            steepness=0.08,   # Gentle transition
            min_score=15,
            max_score=95
        )
        
        # Sentiment adjustments as additive offsets
        sentiment_adjustment = 0
        
        # èè³‡å¤§æ¸› = ç±Œç¢¼æ²‰æ¾± (æ•£æˆ¶é€€å‡º â†’ æ­£é¢ä¿¡è™Ÿ)
        if 'èè³‡å¤§æ¸›' in margin_sentiment:
            sentiment_adjustment += 12
        
        # èåˆ¸å¤§å¢ = è»‹ç©ºæ½›åŠ› (åšç©ºå¢åŠ  â†’ å¯èƒ½åè½‰ â†’ æ­£é¢)
        if 'èåˆ¸å¤§å¢' in margin_sentiment:
            sentiment_adjustment += 8
        
        # èè³‡å¤§å¢ = æ•£æˆ¶è¿½é«˜ (å±éšªä¿¡è™Ÿ â†’ è² é¢)
        if 'èè³‡å¤§å¢' in margin_sentiment:
            sentiment_adjustment -= 15
        
        # Final margin score with bounds
        scores['margin'] = round(np.clip(base_margin + sentiment_adjustment, 0, 100), 2)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 5. éœé»˜ä½ˆå±€åµæ¸¬ (Stealth Accumulation) - Pre-Breakout Enhancement
        #    ç•¶æ©Ÿæ§‹è²·å…¥ä½†è‚¡åƒ¹å°šæœªæ‹‰å‡æ™‚ = çˆ†ç™¼å‰ä½ˆå±€çš„æœ€ä½³ä¿¡è™Ÿ
        #    åˆ¤æ–·: ç±Œç¢¼æ­£å‘ BUT å‹•èƒ½ä½è¿· = è“„å‹¢å¾…ç™¼
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        stealth_bonus = 0
        
        # æª¢æ¸¬ç±Œç¢¼èˆ‡åƒ¹æ ¼çš„èƒŒé›¢
        ret_12m = self._safe_get(row, 'Return_12M', 0)
        ret_1m = self._safe_get(row, 'Return_1M', 0)
        rs_ratio = self._safe_get(row, 'RS_Ratio', 1.0)
        
        # æ¢ä»¶1: æ©Ÿæ§‹åœ¨è²· (ç±Œç¢¼æ­£å‘)
        is_chip_positive = (qfii_raw > 0 or fund_raw > 0 or 
                           'è²·è¶…' in chip_trend or 'é›™å¤š' in chip_trend)
        
        # æ¢ä»¶2: è‚¡åƒ¹å°šæœªæ‹‰å‡ (å‹•èƒ½ä½è¿·)
        is_price_dormant = (ret_12m < 20 and ret_1m < 5 and rs_ratio < 1.2)
        
        # æ¢ä»¶3: è‚¡åƒ¹è¶…è·Œä½†æ©Ÿæ§‹é€²å ´ (é€†å‹¢ä½ˆå±€)
        is_contrarian_accumulation = (ret_12m < -10 and (qfii_raw > 0 or fund_raw > 0))
        
        if is_chip_positive and is_price_dormant:
            stealth_bonus = 18  # éœé»˜ä½ˆå±€ä¸­ï¼Œçˆ†ç™¼åŠ›é«˜
            scores['stealth_signal'] = 'ğŸ¯ éœé»˜ä½ˆå±€'
        elif is_contrarian_accumulation:
            stealth_bonus = 15  # é€†å‹¢ä½ˆå±€ï¼Œé«˜é¢¨éšªé«˜å ±é…¬
            scores['stealth_signal'] = 'ğŸ”¥ é€†å‹¢ä½ˆå±€'
        elif is_chip_positive and ret_12m < 35:
            stealth_bonus = 8   # ç±Œç¢¼æ­£å‘ä½†å°šæœªéç†±
            scores['stealth_signal'] = 'âœ… ç±Œç¢¼è“„å‹¢'
        else:
            scores['stealth_signal'] = ''
        
        scores['stealth_bonus'] = stealth_bonus
        
        # åŠ æ¬Šå½™ç¸½ (åŠ å…¥éœé»˜ä½ˆå±€åŠ æˆ)
        base_final = (scores['qfii'] * 0.30 +
                     scores['fund'] * 0.22 +
                     scores['trend'] * 0.23 +
                     scores['margin'] * 0.15)
        
        # éœé»˜ä½ˆå±€åŠ æˆ (æœ€é«˜é¡å¤–10åˆ†)
        final = min(100, base_final + stealth_bonus * 0.10 * 100 / 18)
        
        return {'score': round(final, 2), 'details': scores, 'stealth_bonus': stealth_bonus}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å› å­å…­ï¼šç­–ç•¥åŠ æˆ Strategy (8%)ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_strategy_score(self, row: pd.Series, ticker: str) -> dict:
        """
        è¨ˆç®—ç­–ç•¥ä¿¡è™ŸåŠ æˆåˆ†æ•¸
        
        çµ„æˆ:
        - Alpha Stock: +25åˆ† (å‹•èƒ½çˆ†ç™¼)
        - Early Bird: +22åˆ† (æ‹é»æ—©é³¥)
        - Contrarian: +20åˆ† (é€†å‘æ©Ÿæœƒ)
        - Hidden Gem: SSS +25, S +18, A +12
        """
        score = 0
        strategies = []
        details = {}
        
        # 1. Alpha Stock
        is_alpha = row.get('Is_Alpha', False)
        alpha_score = self._safe_get(row, 'Alpha_Score', 0)
        if is_alpha or alpha_score > 0:
            bonus = min(25, alpha_score * 0.3) if alpha_score > 0 else 25
            score += bonus
            strategies.append('ğŸ”¥ Alpha')
            details['alpha'] = bonus
        
        # 2. Early Bird
        is_eb = row.get('Is_EarlyBird', False)
        eb_score = self._safe_get(row, 'EarlyBird_Score', 0)
        if is_eb or eb_score > 0:
            bonus = min(22, eb_score * 0.3) if eb_score > 0 else 22
            score += bonus
            strategies.append('ğŸ’ Early Bird')
            details['early_bird'] = bonus
        
        # 3. Contrarian
        is_con = row.get('Is_Contrarian', False)
        con_score = self._safe_get(row, 'Contrarian_Score', 0)
        if is_con or con_score > 0:
            bonus = min(20, con_score * 0.24) if con_score > 0 else 20
            score += bonus
            strategies.append('ğŸ¯ Contrarian')
            details['contrarian'] = bonus
        
        # 4. Hidden Gem
        is_gem = row.get('Is_HiddenGem', False)
        gem_score = self._safe_get(row, 'Gem_Score', 0)
        gem_type = str(row.get('Gem_Type', ''))
        
        if is_gem or gem_score > 0:
            if 'SSS' in gem_type or gem_score >= 100:
                bonus = 25
                strategies.append('ğŸ’ğŸ’ğŸ’ SSS')
            elif 'Sç´š' in gem_type or gem_score >= 80:
                bonus = 18
                strategies.append('ğŸ’ğŸ’ S')
            elif 'Aç´š' in gem_type or gem_score >= 60:
                bonus = 12
                strategies.append('ğŸ’ A')
            else:
                bonus = 8
                strategies.append('ğŸ’ Gem')
            score += bonus
            details['hidden_gem'] = bonus
        
        # ä¸Šé™100åˆ†
        score = min(100, score)
        
        return {
            'score': round(score, 2),
            'strategies': strategies,
            'strategy_str': ', '.join(strategies) if strategies else '',
            'details': details
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€é¢¨éšªèª¿æ•´ Risk Adjustmentã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_risk_penalty(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—é¢¨éšªæ‰£åˆ†
        
        æ‰£åˆ†é …ç›®:
        - æœ€å¤§å›æ’¤ (0-15åˆ†)
        - ç•¶å‰å›æ’¤ (0-12åˆ†)
        - å¥åº·é¢¨éšª (0-15åˆ†)
        - è³‡ç”¢è†¨è„¹ (0-8åˆ†)
        - å“è³ªè­¦ç¤º (0-10åˆ†)
        """
        penalty = 0
        details = {}
        
        # 1. æœ€å¤§å›æ’¤é¢¨éšª
        max_dd = self._safe_get(row, 'Max_Drawdown', 0)
        if max_dd < -60:
            dd_penalty = 15
        elif max_dd < -50:
            dd_penalty = 12
        elif max_dd < -40:
            dd_penalty = 8
        elif max_dd < -30:
            dd_penalty = 5
        else:
            dd_penalty = 0
        penalty += dd_penalty
        details['max_drawdown'] = dd_penalty
        
        # 2. ç•¶å‰å›æ’¤
        curr_dd = self._safe_get(row, 'Current_Drawdown', 0)
        if curr_dd < -50:
            curr_penalty = 12
        elif curr_dd < -40:
            curr_penalty = 8
        elif curr_dd < -30:
            curr_penalty = 5
        elif curr_dd < -20:
            curr_penalty = 2
        else:
            curr_penalty = 0
        penalty += curr_penalty
        details['current_drawdown'] = curr_penalty
        
        # 3. å¥åº·é¢¨éšª
        health_rating = str(row.get('Health_Rating', ''))
        if 'Fç´š' in health_rating:
            health_penalty = 15
        elif 'Dç´š' in health_rating:
            health_penalty = 10
        elif 'Cç´š' in health_rating and 'é›™æ®º' in health_rating:
            health_penalty = 8
        elif 'Cç´š' in health_rating:
            health_penalty = 4
        else:
            health_penalty = 0
        penalty += health_penalty
        details['health'] = health_penalty
        
        # 4. è³‡ç”¢è†¨è„¹é¢¨éšª
        asset_growth = self._safe_get(row, 'Asset_Growth', 0)
        if asset_growth > 50:
            asset_penalty = 8
        elif asset_growth > 40:
            asset_penalty = 5
        elif asset_growth > 30:
            asset_penalty = 2
        else:
            asset_penalty = 0
        penalty += asset_penalty
        details['asset_growth'] = asset_penalty
        
        # 5. å“è³ªè­¦ç¤º
        quality_warning = row.get('Quality_Warning', False)
        warnings = str(row.get('Warnings', ''))
        if quality_warning or 'ç›ˆé¤˜å“è³ªå·®' in warnings:
            warning_penalty = 10
        elif warnings and len(warnings) > 2:
            warning_penalty = 5
        else:
            warning_penalty = 0
        penalty += warning_penalty
        details['quality_warning'] = warning_penalty
        
        # ä¸Šé™50åˆ†
        penalty = min(50, penalty)
        
        return {'penalty': round(penalty, 2), 'details': details}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€è“„å‹¢å¾…ç™¼è©•åˆ† Coiled Spring Scoreã€‘â­ æ–°å¢
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calc_coiled_spring_score(self, row: pd.Series) -> dict:
        """
        è¨ˆç®—ã€Œè“„å‹¢å¾…ç™¼ã€åˆ†æ•¸ - å°‹æ‰¾çˆ†ç™¼åŠ›å°šæœªé‡‹æ”¾çš„æ½›åŠ›è‚¡
        
        æ ¸å¿ƒé‚è¼¯:
        1. åŸºæœ¬é¢æ­£åœ¨æ”¹å–„ (çµæ§‹æ‹é»ã€å“è³ªæå‡)
        2. ç±Œç¢¼æ­£åœ¨é›†ä¸­ (æ©Ÿæ§‹ä½ˆå±€)
        3. ä½†è‚¡åƒ¹å°šæœªåæ˜  (ä½å‹•èƒ½ã€ä½ä¼°å€¼)
        
        é«˜åˆ†è‚¡ç¥¨ç‰¹å¾µ:
        - çµæ§‹æ”¹å–„ + ç±Œç¢¼é€²å ´ + åƒ¹æ ¼ä½è¿· = å½ˆç°§è“„å‹¢ä¸­
        - é€™é¡è‚¡ç¥¨ä¸€æ—¦å•Ÿå‹•ï¼Œçˆ†ç™¼åŠ›æœ€å¤§
        
        Returns:
            dict: {score, signals, spring_level, details}
        """
        signals = []
        details = {}
        score = 0
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. åŸºæœ¬é¢æ”¹å–„ä¿¡è™Ÿ (å½ˆç°§å…§åŠ›)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # çµæ§‹æ‹é»
        gpm_inflection = row.get('GPM_Inflection', False)
        opm_inflection = row.get('OPM_Inflection', False)
        result_tag = str(row.get('Result_Tag', ''))
        
        if gpm_inflection and opm_inflection:
            score += 25
            signals.append('ğŸ”¥ é›™æ‹é»ç¢ºèª')
            details['dual_inflection'] = True
        elif opm_inflection:
            score += 18
            signals.append('ğŸ“ˆ OPMæ‹é»')
            details['opm_inflection'] = True
        elif gpm_inflection:
            score += 15
            signals.append('ğŸ“ˆ GPMæ‹é»')
            details['gpm_inflection'] = True
        elif 'SSS' in result_tag or 'Sç´š' in result_tag:
            score += 12
            signals.append('â­ çµæ§‹æ”¹å–„')
        
        # ç‡Ÿæ”¶åŠ é€Ÿ
        rev_accel = self._safe_get(row, 'Rev_Acceleration', 0)
        if rev_accel > 5:
            score += 12
            signals.append('ğŸš€ ç‡Ÿæ”¶åŠ é€Ÿ')
            details['rev_acceleration'] = rev_accel
        elif rev_accel > 0:
            score += 6
        
        # F-Score è²¡å‹™å¯¦åŠ›
        f_score = self._safe_get(row, 'F_Score', None)
        if f_score is not None and f_score >= 7:
            score += 10
            signals.append('ğŸ’ª F-Scoreå¼·')
            details['f_score'] = f_score
        elif f_score is not None and f_score >= 5:
            score += 5
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. ç±Œç¢¼ä½ˆå±€ä¿¡è™Ÿ (å½ˆç°§å¼µåŠ›)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        qfii_raw = self._safe_get(row, 'QFII_Net_4W', 0)
        fund_raw = self._safe_get(row, 'Fund_Net_4W', 0)
        chip_trend = str(row.get('Chip_Trend', ''))
        
        # æ©Ÿæ§‹é›™è²·
        if qfii_raw > 0 and fund_raw > 0:
            score += 20
            signals.append('ğŸ›ï¸ æ³•äººé›™è²·')
            details['dual_buying'] = True
        elif qfii_raw > 0:
            score += 12
            signals.append('ğŸŒ å¤–è³‡è²·è¶…')
        elif fund_raw > 0:
            score += 10
            signals.append('ğŸ¦ æŠ•ä¿¡è²·è¶…')
        
        # é›™å¤šè¶¨å‹¢
        if 'é›™å¤š' in chip_trend:
            score += 8
            signals.append('ğŸ“Š ç±Œç¢¼é›™å¤š')
        
        # èè³‡æ¸›å°‘ (ç±Œç¢¼æ²‰æ¾±)
        margin_sentiment = str(row.get('Margin_Sentiment', ''))
        if 'èè³‡å¤§æ¸›' in margin_sentiment:
            score += 8
            signals.append('ğŸ“‰ èè³‡æ²‰æ¾±')
            details['margin_shrinking'] = True
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3. åƒ¹æ ¼å°šæœªåæ˜  (å½ˆç°§å£“ç¸®) - è¶Šä½è¶Šæœ‰æ½›åŠ›
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        ret_12m = self._safe_get(row, 'Return_12M', 0)
        ret_1m = self._safe_get(row, 'Return_1M', 0)
        rs_ratio = self._safe_get(row, 'RS_Ratio', 1.0)
        pe_pct = self._safe_get(row, 'PE_Percentile', 50)
        
        # åƒ¹æ ¼ä½è¿·åŠ åˆ† (çˆ†ç™¼åŠ›æœªé‡‹æ”¾)
        if ret_12m < 0:
            score += 15  # å¹´åº¦è² å ±é…¬ = å½ˆç°§æ·±åº¦å£“ç¸®
            signals.append('ğŸ¯ å¹´åº¦è² å ±é…¬')
            details['annual_down'] = ret_12m
        elif ret_12m < 15:
            score += 10  # æº«å’Œè¡¨ç¾
            signals.append('âš¡ åƒ¹æ ¼å¾…ç™¼')
        elif ret_12m < 30:
            score += 5   # ç•¥æœ‰ä¸Šæ¼²ä½†ä¸éç†±
        else:
            score -= 10  # å·²ç¶“è·‘éäº†ï¼Œæ‰£åˆ†
        
        # RS ä½è¿·åŠ åˆ†
        if rs_ratio < 0.9:
            score += 8   # å¼±æ–¼å¤§ç›¤ = å½ˆç°§è“„å‹¢
            signals.append('ğŸ“Š RSå¾…ç™¼')
        elif rs_ratio < 1.0:
            score += 4
        elif rs_ratio > 1.3:
            score -= 5   # å·²ç¶“å¼·å‹¢ï¼Œæ‰£åˆ†
        
        # ä¼°å€¼ä½è¿·åŠ åˆ†
        if pe_pct < 25:
            score += 10
            signals.append('ğŸ’° ä¼°å€¼ä½æª”')
            details['undervalued'] = True
        elif pe_pct < 40:
            score += 5
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 4. è¨ˆç®—å½ˆç°§ç­‰ç´š
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        score = max(0, min(100, score))
        
        if score >= 70:
            spring_level = 'ğŸ”¥ğŸ”¥ğŸ”¥ æ¥µåº¦è“„å‹¢ (çˆ†ç™¼åŠ›æœ€å¼·)'
        elif score >= 55:
            spring_level = 'ğŸ”¥ğŸ”¥ é«˜åº¦è“„å‹¢'
        elif score >= 40:
            spring_level = 'ğŸ”¥ è“„å‹¢ä¸­'
        elif score >= 25:
            spring_level = 'âš¡ æ­£åœ¨å£“ç¸®'
        else:
            spring_level = 'â¡ï¸ ä¸€èˆ¬'
        
        return {
            'score': round(score, 2),
            'signals': signals,
            'spring_level': spring_level,
            'signal_str': ' | '.join(signals[:4]) if signals else '',  # æœ€å¤šé¡¯ç¤º4å€‹
            'details': details
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€ç¶œåˆè©•åˆ†è¨ˆç®—ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calculate_final_score(self) -> pd.DataFrame:
        """è¨ˆç®—æ‰€æœ‰è‚¡ç¥¨çš„ç¶œåˆè©•åˆ†"""
        print("\nğŸ§® è¨ˆç®—ç¶œåˆè©•åˆ†...")
        
        if self.merged_df is None:
            raise ValueError("è«‹å…ˆåŸ·è¡Œ merge_all_data()")
        
        results = []
        
        for idx, row in self.merged_df.iterrows():
            ticker = row['Ticker']
            company = row.get('Company_Name', self.stock_names.get(ticker, ''))
            
            # è¨ˆç®—å„å› å­åˆ†æ•¸
            momentum = self.calc_momentum_score(row)
            quality = self.calc_quality_score(row)
            structural = self.calc_structural_score(row)
            valuation = self.calc_valuation_score(row)
            chip = self.calc_chip_score(row)
            strategy = self.calc_strategy_score(row, ticker)
            risk = self.calc_risk_penalty(row)
            coiled_spring = self.calc_coiled_spring_score(row)  # â­ æ–°å¢
            
            # åŠ æ¬Šè¨ˆç®—æœ€çµ‚åˆ†æ•¸
            raw_score = (
                momentum['score'] * self.WEIGHTS['momentum'] +
                quality['score'] * self.WEIGHTS['quality'] +
                structural['score'] * self.WEIGHTS['structural'] +
                valuation['score'] * self.WEIGHTS['valuation'] +
                chip['score'] * self.WEIGHTS['chip'] +
                strategy['score'] * self.WEIGHTS['strategy']
            )
            
            # â­ è“„å‹¢å¾…ç™¼åŠ æˆ (Pre-Breakout Bonus)
            # é«˜è“„å‹¢åˆ†æ•¸çš„è‚¡ç¥¨é¡å¤–åŠ åˆ†ï¼Œæœ€é«˜ +10 åˆ†
            spring_bonus = coiled_spring['score'] * 0.10 if coiled_spring['score'] >= 40 else 0
            
            # é¢¨éšªèª¿æ•´
            final_score = raw_score + spring_bonus - risk['penalty'] * 0.25
            final_score = max(0, min(100, final_score))
            
            # æŠ•è³‡å»ºè­°
            if final_score >= 75:
                recommendation = 'ğŸ”¥ å¼·åŠ›è²·é€²'
                rec_level = 5
            elif final_score >= 65:
                recommendation = 'ğŸ“ˆ ç©æ¥µé…ç½®'
                rec_level = 4
            elif final_score >= 55:
                recommendation = 'âœ… ç©©å¥æŒæœ‰'
                rec_level = 3
            elif final_score >= 45:
                recommendation = 'âš ï¸ è¬¹æ…è§€æœ›'
                rec_level = 2
            else:
                recommendation = 'ğŸ›‘ å»ºè­°è¿´é¿'
                rec_level = 1
            
            results.append({
                'Ticker': ticker,
                'Company_Name': company,
                'Final_Score': round(final_score, 2),
                'Raw_Score': round(raw_score, 2),
                'Recommendation': recommendation,
                'Rec_Level': rec_level,
                'Strategy': strategy['strategy_str'],
                
                # å…­å¤§å› å­åˆ†æ•¸
                'Momentum': momentum['score'],
                'Quality': quality['score'],
                'Structural': structural['score'],
                'Valuation': valuation['score'],
                'Chip': chip['score'],
                'Strategy_Bonus': strategy['score'],
                'Risk_Penalty': risk['penalty'],
                
                # â­ è“„å‹¢å¾…ç™¼åˆ†æ (æ–°å¢)
                'Coiled_Spring': coiled_spring['score'],
                'Spring_Level': coiled_spring['spring_level'],
                'Spring_Signals': coiled_spring['signal_str'],
                'Spring_Bonus': round(spring_bonus, 2),
                
                # é—œéµæŒ‡æ¨™
                'Health_Rating': row.get('Health_Rating', ''),
                'Decision': row.get('Decision', ''),
                'Result_Tag': row.get('Result_Tag', ''),
                'Gem_Type': row.get('Gem_Type', ''),
                
                # åƒ¹æ ¼èˆ‡ä¼°å€¼
                'Current_Price': row.get('Current_Price', ''),
                'PE': row.get('PE', ''),
                'PE_Percentile': row.get('PE_Percentile', ''),
                'PB_Percentile': row.get('PB_Percentile', ''),
                
                # å‹•èƒ½
                'Momentum_12_1': row.get('Momentum_12_1', ''),
                'Return_12M': row.get('Return_12M', ''),
                'RS_Ratio': row.get('RS_Ratio', ''),
                
                # ç±Œç¢¼
                'QFII_Net_4W': row.get('QFII_Net_4W', ''),
                'Fund_Net_4W': row.get('Fund_Net_4W', ''),
                'Chip_Trend': row.get('Chip_Trend', ''),
                
                # é¢¨éšª
                'Max_Drawdown': row.get('Max_Drawdown', ''),
                'Current_Drawdown': row.get('Current_Drawdown', ''),
                
                # åŸå§‹åˆ†æ•¸ (ç”¨æ–¼æ¯”è¼ƒ)
                'Composite_Score': row.get('Composite_Score', ''),
                'Cross_Composite_Score': row.get('Cross_Composite_Score', ''),
            })
        
        # æ’åºä¸¦åŠ å…¥æ’å
        result_df = pd.DataFrame(results)
        result_df = result_df.sort_values('Final_Score', ascending=False).reset_index(drop=True)
        result_df.insert(0, 'Rank', range(1, len(result_df) + 1))
        
        self.final_ranking = result_df
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total': len(result_df),
            'strong_buy': len(result_df[result_df['Rec_Level'] == 5]),
            'accumulate': len(result_df[result_df['Rec_Level'] == 4]),
            'hold': len(result_df[result_df['Rec_Level'] == 3]),
            'caution': len(result_df[result_df['Rec_Level'] == 2]),
            'avoid': len(result_df[result_df['Rec_Level'] == 1]),
            'avg_score': result_df['Final_Score'].mean(),
            'median_score': result_df['Final_Score'].median(),
        }
        
        print(f"  âœ… è©•åˆ†å®Œæˆ: {len(result_df)} ç­†")
        return result_df
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€è¼¸å‡ºèˆ‡å ±å‘Šã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def print_ranking(self, top_n: int = 30):
        """å°å‡ºè©³ç´°æ’åå ±å‘Š"""
        if self.final_ranking is None:
            print("âŒ è«‹å…ˆåŸ·è¡Œåˆ†æ")
            return
        
        df = self.final_ranking
        
        # æ¨™é¡Œ
        print("\n" + "â•" * 100)
        print(f"{'':^100}")
        print(f"{'ğŸ“Š è‚¡ç¥¨æ± ç¶œåˆæ’åå ±å‘Š v2.0':^95}")
        print(f"{'':^100}")
        print(f"{'Generated: ' + datetime.now().strftime('%Y-%m-%d %H:%M:%S'):^100}")
        print("â•" * 100)
        
        # æ¬Šé‡èªªæ˜
        print("\nã€å› å­æ¬Šé‡é…ç½®ã€‘")
        print(f"  å‹•èƒ½ {self.WEIGHTS['momentum']*100:.0f}% | å“è³ª {self.WEIGHTS['quality']*100:.0f}% | "
              f"çµæ§‹ {self.WEIGHTS['structural']*100:.0f}% | ä¼°å€¼ {self.WEIGHTS['valuation']*100:.0f}% | "
              f"ç±Œç¢¼ {self.WEIGHTS['chip']*100:.0f}% | ç­–ç•¥ {self.WEIGHTS['strategy']*100:.0f}%")
        
        # çµ±è¨ˆæ‘˜è¦
        print("\nã€åˆ†ç´šçµ±è¨ˆã€‘")
        for rec, count_key, emoji in [
            ('å¼·åŠ›è²·é€²', 'strong_buy', 'ğŸ”¥'),
            ('ç©æ¥µé…ç½®', 'accumulate', 'ğŸ“ˆ'),
            ('ç©©å¥æŒæœ‰', 'hold', 'âœ…'),
            ('è¬¹æ…è§€æœ›', 'caution', 'âš ï¸'),
            ('å»ºè­°è¿´é¿', 'avoid', 'ğŸ›‘'),
        ]:
            count = self.stats[count_key]
            pct = count / self.stats['total'] * 100
            bar = 'â–ˆ' * int(pct / 5)
            print(f"  {emoji} {rec}: {count:>3} æª” ({pct:>5.1f}%) {bar}")
        
        print(f"\n  å¹³å‡åˆ†æ•¸: {self.stats['avg_score']:.1f} | ä¸­ä½æ•¸: {self.stats['median_score']:.1f}")
        
        # TOP N æ’å
        print("\n" + "â”€" * 100)
        print(f"{'ğŸ† TOP ' + str(top_n) + ' æ’å':^50}")
        print("â”€" * 100)
        print(f"{'Rank':<5} {'Ticker':<12} {'åç¨±':<8} {'ç¸½åˆ†':>6} {'å»ºè­°':<12} "
              f"{'å‹•èƒ½':>5} {'å“è³ª':>5} {'çµæ§‹':>5} {'ä¼°å€¼':>5} {'ç­–ç•¥':<20}")
        print("â”€" * 100)
        
        for _, row in df.head(top_n).iterrows():
            strategy_short = row['Strategy'][:18] + '...' if len(str(row['Strategy'])) > 20 else row['Strategy']
            print(f"{row['Rank']:<5} {row['Ticker']:<12} {row['Company_Name']:<8} "
                  f"{row['Final_Score']:>6.1f} {row['Recommendation']:<12} "
                  f"{row['Momentum']:>5.0f} {row['Quality']:>5.0f} {row['Structural']:>5.0f} "
                  f"{row['Valuation']:>5.0f} {strategy_short:<20}")
        
        print("â”€" * 100)
        
        # TOP 10 è©³ç´°åˆ†æ
        print("\n" + "â•" * 100)
        print("ğŸ”¥ TOP 10 è©³ç´°åˆ†æ")
        print("â•" * 100)
        
        for _, row in df.head(10).iterrows():
            print(f"\nã€#{row['Rank']} {row['Ticker']} {row['Company_Name']}ã€‘")
            print(f"  ğŸ“Š ç¸½åˆ†: {row['Final_Score']:.2f} (åŸå§‹: {row['Raw_Score']:.2f}) | {row['Recommendation']}")
            print(f"  ğŸ¯ ç­–ç•¥: {row['Strategy'] if row['Strategy'] else 'ç„¡ç‰¹æ®Šç­–ç•¥'}")
            print(f"  ğŸ“ˆ å‹•èƒ½: {row['Momentum']:.0f} | å“è³ª: {row['Quality']:.0f} | "
                  f"çµæ§‹: {row['Structural']:.0f} | ä¼°å€¼: {row['Valuation']:.0f} | ç±Œç¢¼: {row['Chip']:.0f}")
            print(f"  ğŸ”– å¥åº·: {row['Health_Rating']} | æ±ºç­–: {row['Decision']}")
            if row['Current_Price']:
                print(f"  ğŸ’° ç¾åƒ¹: {row['Current_Price']} | PEç™¾åˆ†ä½: {row['PE_Percentile']}%")
            if row['Chip_Trend']:
                print(f"  ğŸ¦ ç±Œç¢¼: {row['Chip_Trend']} | å¤–è³‡4é€±: {row['QFII_Net_4W']}")
        
        # ç­–ç•¥åˆ†é¡
        print("\n" + "â•" * 100)
        print("ğŸ“Œ å„ç­–ç•¥æ¨è–¦")
        print("â•" * 100)
        
        strategy_groups = {
            'ğŸ”¥ Alpha Stock': 'Alpha',
            'ğŸ’ Hidden Gem': 'ğŸ’',
            'ğŸ’ Early Bird': 'Early Bird',
            'ğŸ¯ Contrarian': 'Contrarian',
        }
        
        for display_name, filter_key in strategy_groups.items():
            strategy_df = df[df['Strategy'].str.contains(filter_key, na=False)]
            if len(strategy_df) > 0:
                print(f"\n{display_name} ({len(strategy_df)} æª”):")
                for _, row in strategy_df.head(5).iterrows():
                    print(f"  #{row['Rank']:>3} {row['Ticker']:<10} {row['Company_Name']:<8} "
                          f"- {row['Final_Score']:.1f}åˆ† | {row['Recommendation']}")
        
        # æ‡‰è¿´é¿åå–®
        avoid_df = df[df['Rec_Level'] == 1]
        if len(avoid_df) > 0:
            print(f"\nâš ï¸ æ‡‰è¿´é¿åå–® ({len(avoid_df)} æª”):")
            for _, row in avoid_df.head(5).iterrows():
                print(f"  {row['Ticker']:<10} {row['Company_Name']:<8} "
                      f"- åˆ†æ•¸: {row['Final_Score']:.1f} | é¢¨éšªæ‰£åˆ†: {row['Risk_Penalty']:.0f}")
        
        print("\n" + "â•" * 100)
        print("âœ… åˆ†æå®Œæˆ!")
        print("â•" * 100)
    
    def export_results(self, filename: str = None) -> Path:
        """åŒ¯å‡ºçµæœåˆ° CSV"""
        if self.final_ranking is None:
            print("âŒ è«‹å…ˆåŸ·è¡Œåˆ†æ")
            return None
        
        if filename is None:
            filename = f"master_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        output_path = self.stock_pool_path / filename
        self.final_ranking.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… çµæœå·²åŒ¯å‡º: {output_path}")
        return output_path
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€ä¸»æµç¨‹ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def analyze(self, export: bool = True, top_n: int = 30) -> pd.DataFrame:
        """åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("\n" + "ğŸš€" * 25)
        print("   MASTER RANKING ANALYZER v2.0 - ç¶œåˆæ’ååˆ†æå™¨ï¼ˆçµ‚æ¥µç‰ˆï¼‰")
        print("ğŸš€" * 25 + "\n")
        
        # Step 1: è¼‰å…¥æ‰€æœ‰æ•¸æ“š
        self.load_all_data()
        
        # Step 2: åˆä½µæ•¸æ“š
        self.merge_all_data()
        
        # Step 3: è¨ˆç®—åˆ†æ•¸
        self.calculate_final_score()
        
        # Step 4: å°å‡ºå ±å‘Š
        self.print_ranking(top_n)
        
        # Step 5: åŒ¯å‡º
        if export:
            self.export_results()
        
        return self.final_ranking
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€ä¾¿æ·æ–¹æ³•ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_top_picks(self, n: int = 10) -> pd.DataFrame:
        """å–å¾—å‰ N åæ¨è–¦"""
        if self.final_ranking is None:
            self.analyze(export=False, top_n=n)
        return self.final_ranking.head(n)
    
    def get_by_strategy(self, strategy: str) -> pd.DataFrame:
        """ä¾ç­–ç•¥ç¯©é¸"""
        if self.final_ranking is None:
            self.analyze(export=False)
        return self.final_ranking[self.final_ranking['Strategy'].str.contains(strategy, na=False)]
    
    def get_strong_buys(self) -> pd.DataFrame:
        """å–å¾—å¼·åŠ›è²·é€²åå–®"""
        if self.final_ranking is None:
            self.analyze(export=False)
        return self.final_ranking[self.final_ranking['Rec_Level'] == 5]
    
    def get_avoid_list(self) -> pd.DataFrame:
        """å–å¾—æ‡‰è¿´é¿åå–®"""
        if self.final_ranking is None:
            self.analyze(export=False)
        return self.final_ranking[self.final_ranking['Rec_Level'] == 1]
    
    def get_by_recommendation(self, rec_level: int) -> pd.DataFrame:
        """ä¾å»ºè­°ç­‰ç´šç¯©é¸ (5=å¼·åŠ›è²·é€², 4=ç©æ¥µé…ç½®, 3=æŒæœ‰, 2=è§€æœ›, 1=è¿´é¿)"""
        if self.final_ranking is None:
            self.analyze(export=False)
        return self.final_ranking[self.final_ranking['Rec_Level'] == rec_level]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã€å·¥å…·å‡½æ•¸ã€‘
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _safe_get(self, row: pd.Series, key: str, default=0):
        """å®‰å…¨å–å¾—æ•¸å€¼"""
        val = row.get(key, default)
        if pd.isna(val):
            return default
        try:
            return float(val)
        except (ValueError, TypeError):
            return default
    
    def _sigmoid_score(self, x: float, midpoint: float, steepness: float = 1.0,
                       min_score: float = 0, max_score: float = 100) -> float:
        """
        Physics-Informed Continuous Scoring via Sigmoid (Logistic) Function
        
        Maps any real-valued input to a smooth score in [min_score, max_score].
        Eliminates boundary effects from discrete thresholds.
        
        Formula: score = min_score + (max_score - min_score) / (1 + exp(-steepness * (x - midpoint)))
        
        Args:
            x: Input value (can be any real number)
            midpoint: The x value at which the function outputs the median score (50th percentile)
            steepness: Controls transition sharpness (higher = steeper curve, lower = gentler)
                       Typical range: 0.01 ~ 5.0 depending on input scale
            min_score: Minimum output score (default: 0)
            max_score: Maximum output score (default: 100)
        
        Returns:
            Continuous score in [min_score, max_score]
        
        Example:
            For momentum scoring with midpoint=0, steepness=0.05:
            - x = -50 â†’ score â‰ˆ 7.6
            - x = 0   â†’ score = 50
            - x = 50  â†’ score â‰ˆ 92.4
        """
        # Clamp extreme values to avoid numerical overflow
        z = steepness * (x - midpoint)
        z = np.clip(z, -500, 500)
        
        sigmoid = 1.0 / (1.0 + np.exp(-z))
        score = min_score + (max_score - min_score) * sigmoid
        
        return round(score, 2)
    
    def _signed_log_transform(self, x: float, base_scale: float = 1000) -> float:
        """
        Signed Log Transform to Compress Outliers (Size-Neutral Normalization)
        
        Applies: sign(x) * log(1 + |x| / base_scale)
        
        This transformation:
        1. Preserves sign (positive/negative sentiment)
        2. Compresses large absolute values (reduces size bias)
        3. Maintains relative ordering
        
        Args:
            x: Raw input value (e.g., QFII net buy in shares)
            base_scale: Normalization factor (controls compression strength)
        
        Returns:
            Transformed value with compressed magnitude
        
        Example (base_scale=1000):
            - x = 100,000 â†’ 4.61
            - x = 10,000  â†’ 2.40
            - x = 1,000   â†’ 0.69
            - x = -50,000 â†’ -3.93
        """
        if x == 0:
            return 0.0
        return np.sign(x) * np.log1p(abs(x) / base_scale)
    
    def _percentile_score(self, x: float, series: pd.Series, invert: bool = False) -> float:
        """
        Percentile-Based Scoring (Rank Normalization)
        
        Converts a value to its percentile rank within a distribution.
        Eliminates absolute value bias by using relative positioning.
        
        Args:
            x: Value to score
            series: Reference distribution (e.g., all stocks' QFII values)
            invert: If True, lower values get higher scores (e.g., for PE)
        
        Returns:
            Score from 0-100 based on percentile rank
        """
        if series is None or len(series) == 0:
            return 50.0
        
        # Calculate percentile rank
        rank = (series < x).sum() / len(series) * 100
        
        if invert:
            rank = 100 - rank
        
        return round(rank, 2)


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    parser = argparse.ArgumentParser(
        description="Master Ranking Analyzer v2.0 - è‚¡ç¥¨æ± ç¶œåˆæ’ååˆ†æå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  python master_ranking_analyzer.py                  # åŸ·è¡Œå®Œæ•´åˆ†æ
  python master_ranking_analyzer.py --top 50         # é¡¯ç¤ºå‰50å
  python master_ranking_analyzer.py --no-export      # ä¸åŒ¯å‡ºCSV
  python master_ranking_analyzer.py --strategy alpha # åªçœ‹Alphaç­–ç•¥
        """
    )
    parser.add_argument('--top', type=int, default=30, help='é¡¯ç¤ºå‰ N å (é è¨­: 30)')
    parser.add_argument('--no-export', action='store_true', help='ä¸åŒ¯å‡ºCSVæª”æ¡ˆ')
    parser.add_argument('--strategy', type=str, help='ä¾ç­–ç•¥ç¯©é¸ (alpha/early/gem/contrarian)')
    parser.add_argument('--avoid', action='store_true', help='é¡¯ç¤ºæ‡‰è¿´é¿åå–®')
    parser.add_argument('--path', type=str, help='Stock_Pool è³‡æ–™å¤¾è·¯å¾‘')
    
    args = parser.parse_args()
    
    # å»ºç«‹åˆ†æå™¨
    analyzer = MasterRankingAnalyzer(args.path)
    
    # åŸ·è¡Œåˆ†æ
    ranking = analyzer.analyze(export=not args.no_export, top_n=args.top)
    
    # é¡å¤–è¼¸å‡º
    if args.strategy:
        strategy_map = {
            'alpha': 'Alpha',
            'early': 'Early Bird',
            'gem': 'ğŸ’',
            'contrarian': 'Contrarian'
        }
        filter_key = strategy_map.get(args.strategy.lower(), args.strategy)
        filtered = analyzer.get_by_strategy(filter_key)
        print(f"\nğŸ“Œ {args.strategy} ç­–ç•¥ç¯©é¸ ({len(filtered)} æª”):")
        for _, row in filtered.head(20).iterrows():
            print(f"  #{row['Rank']:>3} {row['Ticker']:<10} {row['Company_Name']:<8} - {row['Final_Score']:.1f}åˆ†")
    
    if args.avoid:
        avoid = analyzer.get_avoid_list()
        print(f"\nâš ï¸ å®Œæ•´æ‡‰è¿´é¿åå–® ({len(avoid)} æª”):")
        for _, row in avoid.iterrows():
            print(f"  {row['Ticker']:<10} {row['Company_Name']:<8} - åˆ†æ•¸: {row['Final_Score']:.1f}")
    
    return ranking


if __name__ == "__main__":
    main()
